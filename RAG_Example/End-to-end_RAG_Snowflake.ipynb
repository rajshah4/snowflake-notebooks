{"cells":[{"cell_type":"markdown","id":"3024fb79","metadata":{},"source":["## RAG with Snowflake Cortex\n","This is a very simple demo to highlight the Cortex capabilties to build a RAG demo with a Strealit front end.\n","This demo takes a PDF file, chunks it down, and uses it for RAG.\n","It requires pydpf2 for the chunking. I had to install pypdf2-2.10.5 into my local evnironment.\n","The [notebook](https://github.com/sfc-gh-tchristian/snowflake-rag) comes from Tom Christian, also check out the full [article](https://medium.com/@thechosentom/rag-made-simple-with-snowflake-cortex-74d1df5143fd)\n","\n","Another RAG demo that uses 10-Ks is frem Jeremy, check out the [article](https://medium.com/@jeremyjgriffith/retrieval-augmented-generation-rag-application-using-snowflake-cortex-and-streamlit-9cb261e81c2e) and the [Github](https://github.com/jeremyjgriffith/cortex-rag-application)\n","\n","If you are looking to do RAG in Snowflake, instead of building it from parts, go use our [Cortex Search](https://docs.snowflake.com/user-guide/snowflake-cortex/cortex-search/cortex-search-overview) that provides a managed search for RAG. "]},{"cell_type":"code","execution_count":1,"id":"cb6d052c","metadata":{},"outputs":[],"source":["# Import python packages & establish session\n","import pandas as pd\n","from PyPDF2 import PdfFileReader\n","from snowflake.snowpark.files import SnowflakeFile\n","from io import BytesIO\n","from snowflake.snowpark.types import StringType, StructField, StructType\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","import json"]},{"cell_type":"code","execution_count":2,"id":"85ea35d9","metadata":{},"outputs":[],"source":["from snowflake.snowpark.session import Session\n","from snowflake import connector\n","from snowflake.ml.utils import connection_params"]},{"cell_type":"code","execution_count":3,"id":"3775908f-ca36-4846-8f38-5adca39217f2","metadata":{"codeCollapsed":true,"collapsed":true,"language":"python","name":"libs"},"outputs":[],"source":["with open('../creds.json') as f:\n","    data = json.load(f)\n","    USERNAME = data['user']\n","    PASSWORD = data['password']\n","    SF_ACCOUNT = data['account']\n","    SF_WH = data['warehouse']\n","\n","CONNECTION_PARAMETERS = {\n","   \"account\": SF_ACCOUNT,\n","   \"user\": USERNAME,\n","   \"password\": PASSWORD,\n","}\n","\n","session = Session.builder.configs(CONNECTION_PARAMETERS).create()\n","\n","#from snowflake.snowpark.context import get_active_session\n","#session = get_active_session()\n"]},{"cell_type":"markdown","id":"ed0001f3-6291-4a1d-bab2-da39e907cacb","metadata":{"collapsed":false,"name":"intro"},"source":["RAG Made Easy w/ Snowflake Cortex\n","========\n","\n","Creating an end-to-end Retrieval Augmented Generation process (or RAG) directly in Snowflake.\n","1) Extract full text from PDF files using Snowpark.\n","2) Chunk those documents using Langchain in Snowpark.\n","3) Use Cortex to create embeddings of those chunks.\n","4) Use Vector Similarity to show the most similar chunk when prompting an LLM."]},{"cell_type":"markdown","id":"9d86cf9c-f0d1-4834-b143-cb39517071c3","metadata":{"collapsed":false,"language":"sql","name":"show_data"},"source":["Have a stage for the pdfs - you will have to change from the stage name I used"]},{"cell_type":"code","execution_count":5,"id":"f1096fb7-6a33-48fb-8984-772288e650e9","metadata":{"collapsed":false,"language":"python","name":"pdf_read_func"},"outputs":[],"source":["#Create a Snowpark based function to extract text from PDFs\n","\n","def readpdf(file_path):\n","    whole_text = \"\"\n","    with SnowflakeFile.open(file_path, 'rb') as file:\n","        f = BytesIO(file.readall())\n","        pdf_reader = PdfFileReader(f)\n","        whole_text = \"\"\n","        for page in pdf_reader.pages:\n","            whole_text += page.extract_text()\n","    return whole_text"]},{"cell_type":"code","execution_count":6,"id":"c1a5e251-47fa-450a-8667-2c8899796b02","metadata":{"language":"python","name":"UDF_reg"},"outputs":[{"data":{"text/plain":["<snowflake.snowpark.udf.UserDefinedFunction at 0x169794610>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["#Register the UDF. \n","#Optional : Convert the cell to markdown to prevent rerunning later.\n","session.udf.register(\n","    func = readpdf\n","  , return_type = StringType()\n","  , input_types = [StringType()]\n","  , is_permanent = True\n","  , name = 'SNOWPARK_PDF'\n","  , replace = True\n","  , packages=['snowflake-snowpark-python','pypdf2']\n","  , stage_location = 'RAJIV.PUBLIC.RAJ_UDFS'  ###set this to your stage\n",")"]},{"cell_type":"code","execution_count":42,"id":"6ea74c09-b8d0-440d-84d1-fd1cfaef9ce3","metadata":{"collapsed":false,"language":"sql","name":"raw_table"},"outputs":[],"source":["##Make sure you Stage has directory enable - one click in the UI\n","query = \"\"\"CREATE OR REPLACE TABLE RAW_TEXT AS\n","SELECT\n","    relative_path\n","    , file_url\n","    , snowpark_pdf(build_scoped_file_url(@RAJ_UDFS, relative_path)) as raw_text\n","from directory(@RAJ_UDFS);\"\"\""]},{"cell_type":"code","execution_count":43,"id":"a7a977ab","metadata":{},"outputs":[{"data":{"text/plain":["[Row(status='Table RAW_TEXT successfully created.')]"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["session.sql(query).collect()"]},{"cell_type":"code","execution_count":null,"id":"e633b10e-8255-4e67-ad98-0d2704af274a","metadata":{"collapsed":false,"language":"sql","name":"too_big_sadness"},"outputs":[],"source":["query = \"\"\" --Optional : This will fail due to tokens exceeding limit, which means we need to chunk!\n","SELECT\n","SNOWFLAKE.ML.COMPLETE('llama2-7b-chat',CONCAT('summarise the following text',raw_text)) \n","FROM\n","RAW_TEXT\n","LIMIT 1;\"\"\"\n","\n","session.sql(query).collect()\n","\n","##This should fail if you are using a large document"]},{"cell_type":"markdown","id":"4b06bb86-7434-4b11-aee4-41af529095c7","metadata":{"collapsed":false,"name":"word_on_chunking"},"source":["A note on chunking\n","-----\n","Chunking is the process of splitting a large body of text into smaller 'chunks' whilst attempting to keep as much relevant information as possible. Make the chunks too small and you run the risk of removing key information that the model requires to answer the question. Too large and it may be harder to retreive the correct body of text from the vector search - or spend tokens excessively.\n","\n","There are many strategies towards chunking. Eg - pass the most relevant, top n relevant chunks, or pass the most relevent chunk + the chunk either side of that one. Play around and see what works for your use case!\n"]},{"cell_type":"code","execution_count":45,"id":"5de470cc-255e-42fa-87b8-fcac62040b41","metadata":{"collapsed":false,"language":"python","name":"chunker_udtf"},"outputs":[],"source":["#A class for chunking text and returning a table via UDTF\n","class text_chunker:\n","\n","    def process(self,text):        \n","        text_raw=[]\n","        text_raw.append(text) \n","        \n","        text_splitter = RecursiveCharacterTextSplitter(\n","            separators = [\"\\n\"], # Define an appropriate separator. New line is good typically!\n","            chunk_size = 1000, #Adjust this as you see fit\n","            chunk_overlap  = 50, #This let's text have some form of overlap. Useful for keeping chunks contextual\n","            length_function = len,\n","            add_start_index = True #Optional but useful if you'd like to feed the chunk before/after\n","        )\n","    \n","        chunks = text_splitter.create_documents(text_raw)\n","        df = pd.DataFrame(chunks, columns=['chunks','meta'])\n","        \n","        yield from df.itertuples(index=False, name=None)\n"]},{"cell_type":"code","execution_count":46,"id":"c9c88000-ba6b-4fe9-9215-8a2e4720948d","metadata":{"collapsed":false,"language":"python","name":"reg_chunk_udtf"},"outputs":[{"data":{"text/plain":["<snowflake.snowpark.udtf.UserDefinedTableFunction at 0x149926d90>"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["#Register the UDTF - set the stage location\n","\n","schema = StructType([\n","     StructField(\"chunk\", StringType()),\n","    StructField(\"meta\", StringType()),\n"," ])\n","\n","session.udtf.register( \n","    handler = text_chunker,\n","    output_schema= schema, \n","    input_types = [StringType()] , \n","    is_permanent = True , \n","    name = 'CHUNK_TEXT' , \n","    replace = True , \n","    packages=['pandas','langchain'], stage_location = 'RAJIV.PUBLIC.RAJ_UDFS' )"]},{"cell_type":"code","execution_count":47,"id":"1b744312","metadata":{},"outputs":[{"data":{"text/plain":["[Row(status='Table CHUNK_TEXT successfully created.')]"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["query = \"\"\"\n","\n","--Create the chunked version of the table\n","CREATE OR REPLACE TABLE CHUNK_TEXT AS\n","SELECT\n","        relative_path,\n","        func.*\n","    FROM raw_text AS raw,\n","         TABLE(chunk_text(raw_text)) as func;\n","\n","\"\"\"\n","\n","session.sql(query).collect()"]},{"cell_type":"code","execution_count":48,"id":"9163f7ac","metadata":{},"outputs":[{"data":{"text/plain":["[Row(status='Table VECTOR_STORE successfully created.')]"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["query = \"\"\"\n","--Convert your chunks to embeddings\n","CREATE OR REPLACE TABLE VECTOR_STORE AS\n","SELECT\n","RELATIVE_PATH as EPISODE_NAME,\n","CHUNK AS CHUNK,\n","snowflake.ml.embed_text('e5-base-v2', chunk) as chunk_embedding\n","FROM CHUNK_TEXT;\n","\"\"\"\n","\n","session.sql(query).collect()"]},{"cell_type":"code","execution_count":49,"id":"8692b7e2","metadata":{},"outputs":[{"data":{"text/plain":["[Row(EPISODE_NAME='TRANSCRIPT_-Snowflake-Inc-SNOW-US-Q3-2024-Earnings-Call-29-November-2023-5_00-PM-ET.pdf', CHUNK='(\\'page_content\\', \"Meanwhile, Snowflake has announced and showcased a plethora of new technologies that let customers mobilize \\\\nAI. We\\'ve introduced Snowflake Cortex to leverage AI and machine learning on Snowflake. Cortex is a manage d \\\\nservice for inferencing large language models. This opens up direct access to models and specialized operations \\\\nlike translation, sentiment and vector functions. Business analysts and data engineers can now use AI \\\\nfunctionality without the fractured high ly technical challenges of the AI landscape.  \\\\n \\\\nLast summer, we introduced Snowpark Container Services, which also serves as the second pillar of our AI \\\\nenablement strategy. Developers can access any language, any library and flexible hardware inside the \\\\ngovernance boundary of Snowflake. More than 70 customers are already using Container Services in preview, \\\\nwith many more waiting in line. Snowflake makes the common AI use case as easy and the advanced use case\")')]"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["query = \"\"\"\n","--Vector distance allows use to find the most similar chunk to a question\n","SELECT EPISODE_NAME, CHUNK from RAJIV.PUBLIC.VECTOR_STORE \n","            ORDER BY VECTOR_L2_DISTANCE(\n","            snowflake.ml.embed_text('e5-base-v2', \n","            'What is Snowflake doing of AI/ML?'\n","            ), CHUNK_EMBEDDING\n","            ) limit 1\n","        ;\n","\"\"\"\n","\n","session.sql(query).collect()"]},{"cell_type":"code","execution_count":null,"id":"1d13a4b9","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":53,"id":"cef9fd06","metadata":{},"outputs":[],"source":["query = \"\"\"\n","--Pass the chunk we need along with the prompt to get a better structured answer from the LLM\n","SELECT snowflake.ml.complete(\n","    'llama2-7b-chat', \n","     CONCAT( \n","        'Answer the question based on the context. Be concise.','Context: ',\n","        (\n","            SELECT chunk FROM vector_Store \n","            ORDER BY vector_l2_distance(\n","            snowflake.ml.embed_text('e5-base-v2', \n","            'What is Snowflake doing for AI/ML?'\n","            ), chunk_embedding\n","            ) LIMIT 1\n","        ),\n","        'Question: What is Snowflake doing for AI/ML?',\n","        'Answer: '\n","    )\n",") as response;\n","\"\"\"\n","\n","response = session.sql(query).collect()"]},{"cell_type":"code","execution_count":54,"id":"27a69568","metadata":{},"outputs":[{"data":{"text/plain":["[Row(RESPONSE=' Based on the context, Snowflake is providing several new technologies to enable AI and machine learning (ML) for its customers. These include:\\n\\n1. Snowflake Cortex: A managed service for inferencing large language models, providing direct access to models and specialized operations like translation, sentiment, and vector functions.\\n2. Snowpark Container Services: A platform that allows developers to access any language, any library, and flexible hardware within the governance boundary of Snowflake, making it easier for business analysts and data engineers to use AI functionality without technical challenges.')]"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["response"]},{"cell_type":"markdown","id":"9d887feb","metadata":{},"source":["Streamlit app to use inside Snowflake"]},{"cell_type":"code","execution_count":null,"id":"f68380a5","metadata":{},"outputs":[],"source":["## Stramlit Code\n","\n","import streamlit as st # Import python packages\n","from snowflake.snowpark.context import get_active_session\n","session = get_active_session() # Get the current credentials\n","\n","st.title(\"Ask Your Data Anything :snowflake:\")\n","st.write(\"\"\"Built using end-to-end RAG in Snowflake with Cortex functions.\"\"\")\n","\n","model = st.selectbox('Select your model:',('llama2-70b-chat','mistral-7b'))\n","\n","prompt = st.text_input(\"Enter prompt\", placeholder=\"What makes time perceived to be slower?\", label_visibility=\"collapsed\")\n","\n","quest_q = f'''\n","select snowflake.ml.complete(\n","    '{model}', \n","    concat( \n","        'Answer the question based on the context. Be concise.','Context: ',\n","        (\n","            select chunk from LLM_DEMO.PODCASTS.VECTOR_STORE \n","            order by vector_l2_distance(\n","            snowflake.ml.embed_text('e5-base-v2', \n","            '{prompt}'\n","            ), chunk_embedding\n","            ) limit 1\n","        ),\n","        'Question: ', \n","        '{prompt}',\n","        'Answer: '\n","    )\n",") as response;\n","'''\n","\n","if prompt:\n","    df_query = session.sql(quest_q).to_pandas()\n","    st.write(df_query['RESPONSE'][0])"]}],"metadata":{"kernelspec":{"display_name":"working38","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":5}
