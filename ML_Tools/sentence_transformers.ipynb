{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bff18a27-f071-4ee8-80f4-e0ca3b4a2e88",
   "metadata": {
    "collapsed": false,
    "name": "cell2"
   },
   "source": [
    "# Selecting and Speeding up your Sentence Transformer Model\n",
    "\n",
    "This notebooks walks you through the process of selecting a [Sentence Transformer](https://www.sbert.net/) model by considering tradeffs between speed and performance. You can start by browsing Hugging Face and using the [Massive Text Embedding Benchmark](https://huggingface.co/blog/mteb) to select a model that fits your task/size needs.\n",
    "Once you have selected a model, we will show you how to speed up the model with a couple of techniques including batching, ONNX, and a optimized container.\n",
    "\n",
    "There is also an accompany short video that covers the same content: [Selecting and Speeding up your Sentence Transformer Model](https://www.youtube.com/watch?v=WQqAN4k3R4g&t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba64bab-c24b-4d2d-800d-3772e9023cfa",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers[train] model2vec snowflake-ml-python==1.6.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e2e3a7",
   "metadata": {},
   "source": [
    "I am going to run the models on a GPU, so we will need this ONNX library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba52f01d-5a2a-4eb1-9d8a-6a99fc09eb17",
   "metadata": {
    "language": "python",
    "name": "cell51"
   },
   "outputs": [],
   "source": [
    "!pip install -q optimum[onnxruntime-gpu] ## Going to use GPU ONNX for some comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91504dc0-ab97-46b9-9c8d-148545d3755f",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.models import StaticEmbedding\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e52936d-713b-4a27-b530-ad5d17fafad1",
   "metadata": {
    "collapsed": false,
    "name": "cell6"
   },
   "source": [
    "## Get some data\n",
    "I am going to use two datasets:\n",
    "- A synthetically generated dataset of 100,000 random sentences \n",
    "- A dataset of Amazon reviews\n",
    "\n",
    "Ideally you will evaluate on your own task / dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a6ef0e",
   "metadata": {},
   "source": [
    "Generate a synthetic dataset of random sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768af56d-f6c6-4752-b756-99d3083a674f",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "def generate_random_sentences(num_sentences, vocab):\n",
    "    return [' '.join(random.choices(vocab, k=random.randint(5, 15))) for _ in range(num_sentences)]\n",
    "\n",
    "# Create a simple vocabulary for random sentence generation\n",
    "vocab = ['apple', 'banana', 'car', 'dog', 'elephant', 'fruit', 'giraffe', 'hat', 'ice', 'jungle', 'kite', \n",
    "         'lemon', 'monkey', 'notebook', 'orange', 'pizza', 'queen', 'river', 'sun', 'tree', 'umbrella', \n",
    "         'violin', 'water', 'x-ray', 'yacht', 'zebra']\n",
    "\n",
    "# Generate 100,000 random sentences for scale testing - you can always increase this\n",
    "num_sentences = 100000\n",
    "sentences = generate_random_sentences(num_sentences, vocab)\n",
    "\n",
    "#if you want to test using dataframes\n",
    "df = pd.DataFrame(sentences)\n",
    "df.columns = ['SENTENCES']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590deb69",
   "metadata": {},
   "source": [
    "Amazon review dataset from [Hugging Face text classification](https://huggingface.co/datasets?task_categories=task_categories:text-classification&sort=trending) datasets. For this notebook, I limit this to 100k for test/train. If you want to test at larger scales, you can easily change the `num_samples` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca579a-2575-4e64-845e-c30bc0307116",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell22"
   },
   "outputs": [],
   "source": [
    "ds = load_dataset(\"fancyzhx/amazon_polarity\")\n",
    "\n",
    "num_samples = 100000\n",
    "\n",
    "# Extract the train and test splits\n",
    "train_data = ds['train'].select(range(min(len(ds['train']), num_samples)))\n",
    "test_data = ds['test'].select(range(min(len(ds['test']), num_samples)))\n",
    "\n",
    "# Extract text features and labels from the dataset\n",
    "train_texts = train_data['content']  # Assuming 'content' contains the text data\n",
    "train_labels = train_data['label']   # Assuming 'label' contains the labels\n",
    "test_texts = test_data['content']\n",
    "test_labels = test_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02c246a-8e2e-41a2-9b8a-5ea356a1b7e1",
   "metadata": {
    "collapsed": false,
    "name": "cell9"
   },
   "source": [
    "# Evaluate Models on Speed and Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d16733b",
   "metadata": {},
   "source": [
    "I have a script here that will evaluate the models on speed and accuracy. It measures\n",
    "- Time to encode 100,000 sentences\n",
    "- Computing pairwise cosine similarity between 100,000 sentences\n",
    "- Time to encode Amazon review dataset\n",
    "- Text classification metrics for the Amazon review dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9385bf80",
   "metadata": {},
   "source": [
    "I evaluate three different types of models here (but feel free to add more):\n",
    "- Static Embedding Model (similar to Word2Vec)\n",
    "- MiniLM - small language model fine tuned for sentence transformers\n",
    "- GTE large model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10162a15-0d8f-45b5-be01-819e2e790877",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "#model = SentenceTransformer(\"tomaarsen/static-bert-uncased-gooaq\")\n",
    "#model = SentenceTransformer('Alibaba-NLP/gte-large-en-v1.5', trust_remote_code=True)\n",
    "\n",
    "\n",
    "# Measure encoding time for random sentences\n",
    "start_time = time.time()\n",
    "embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "end_time = time.time()\n",
    "#print(f\"Time taken to encode {num_sentences} sentences: {end_time - start_time} seconds\")\n",
    "\n",
    "# Compute pairwise similarities on a subset of the embeddings for testing\n",
    "start_time = time.time()\n",
    "#similarity_scores = util.pytorch_cos_sim(embeddings[:10000], embeddings[:10000])\n",
    "end_time = time.time()\n",
    "#print(f\"Time taken to compute similarity for 10000 pairs: {end_time - start_time} seconds\")\n",
    "\n",
    "# Measure encoding time for Amazon Review dataset\n",
    "start_time = time.time()\n",
    "train_embeddings_model = model.encode(train_texts, convert_to_tensor=True)\n",
    "test_embeddings_model = model.encode(test_texts, convert_to_tensor=True)\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to encode {num_samples} reviews dataset: {end_time - start_time} seconds\")\n",
    "\n",
    "train_embeddings = train_embeddings_model.cpu().numpy()\n",
    "test_embeddings = test_embeddings_model.cpu().numpy()\n",
    "# Scale the embeddings (standardization)\n",
    "scaler = StandardScaler()\n",
    "train_embeddings_scaled = scaler.fit_transform(train_embeddings)\n",
    "test_embeddings_scaled = scaler.transform(test_embeddings)\n",
    "\n",
    "# Train a logistic regression classifier with increased iterations and different solver\n",
    "classifier = LogisticRegression(max_iter=500, solver='saga')  # Increased iterations and different solver\n",
    "classifier.fit(train_embeddings_scaled, train_labels)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = classifier.predict(test_embeddings_scaled)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "classification_rep = classification_report(test_labels, predictions)\n",
    "roc_auc = roc_auc_score(test_labels, classifier.predict_proba(test_embeddings_scaled)[:, 1], multi_class='ovr')\n",
    "conf_matrix = confusion_matrix(test_labels, predictions)\n",
    "\n",
    "# Display metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_rep)\n",
    "print(f'ROC AUC: {roc_auc:.4f}')\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7397da38",
   "metadata": {},
   "source": [
    "The results - you can see the traaeoffs between speed and accuracy.\n",
    "\n",
    "Static Embedding Model - tomaarsen/static-bert-uncased-gooaq  \n",
    "Time taken to encode Amazon Reviews: 19 seconds   \n",
    "Text Classification Accuracy: 0.8009  \n",
    "ROC AUC: 0.8808\n",
    "\n",
    "Sentence Transformers - all-MiniLM-L6-v2  \n",
    "Time taken to encode Amazon Reviews: 71 seconds    \n",
    "Text Classification Accuracy: 0.8279  \n",
    "ROC AUC: 0.9062\n",
    "\n",
    "Sentence Transformers - Alibaba-NLP/gte-large-en-v1.5  \n",
    "Time taken to encode Amazon Reviews: 1384 seconds   \n",
    "Text Classification Accuracy: 0.9620   \n",
    "ROC AUC: 0.9909 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b4c48c-a5d6-438f-854a-7da6d83dc338",
   "metadata": {
    "collapsed": false,
    "name": "cell49"
   },
   "source": [
    "# Speeding up the model\n",
    "\n",
    "Here are a few easy techniques you can use to speed up the models\n",
    "- Use Batching\n",
    "- Using ONNX\n",
    "- Using a optimized container - for example, [Text Embedding Inference Container](https://github.com/huggingface/text-embeddings-inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec278c6f-a2ad-4502-94ba-cbe7e8b71d9f",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell40"
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Measure encoding time for random sentences\n",
    "start_time = time.time()\n",
    "embeddings = model.encode(df['SENTENCES'], convert_to_tensor=True)\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to encode {num_sentences} sentences: {end_time - start_time} seconds\")\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# Measure encoding time for random sentences\n",
    "start_time = time.time()\n",
    "embeddings = model.encode(df['SENTENCES'], convert_to_tensor=True, batch_size=256, show_progress_bar=True)\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to encode {num_sentences} sentences using batches: {end_time - start_time} seconds\")\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", backend=\"onnx\")\n",
    "# Measure encoding time for random sentences\n",
    "start_time = time.time()\n",
    "embeddings = model.encode(df['SENTENCES'], convert_to_tensor=True, show_progress_bar=True)\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to encode {num_sentences} sentences with ONNX: {end_time - start_time} seconds\")\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", backend=\"onnx\")\n",
    "# Measure encoding time for random sentences\n",
    "start_time = time.time()\n",
    "embeddings = model.encode(df['SENTENCES'], convert_to_tensor=True, batch_size=256, show_progress_bar=True)\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to encode {num_sentences} sentences with ONNX in Batches: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d5fd06",
   "metadata": {},
   "source": [
    "Results:\n",
    "Time taken to encode 100000 sentences: 17.990296125411987 seconds  \n",
    "Time taken to encode 100000 sentences using batches: 5.701428413391113 seconds   \n",
    "Time taken to encode 100000 sentences with ONNX: 12.300400495529175 seconds  \n",
    "Time taken to encode 100000 sentences with ONNX in Batches: 8.326634883880615 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10253cd-deac-420f-9db5-def27aeed292",
   "metadata": {
    "collapsed": false,
    "name": "cell3"
   },
   "source": [
    "# Visualize Embeddings\n",
    "\n",
    "Visualize the embeddings is very useful for understanding how your embeddings are working. This is a simple example using UMAP. You should visualize as part of your workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906333d3-0a71-4104-a898-9ab26de84823",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell16"
   },
   "outputs": [],
   "source": [
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3482ab76-c6df-49b9-af46-1cbc495e7a55",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "embeddings_2d = reducer.fit_transform(test_embeddings_scaled)\n",
    "\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=test_labels, cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.title('UMAP of Embeddings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d570f0",
   "metadata": {},
   "source": [
    "# Register Sentence Transformers Model in Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b386f8-a0d8-4bfc-aa6c-b4d8d4a18c56",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell36"
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.registry import registry\n",
    "from snowflake.ml.utils.connection_params import SnowflakeLoginOptions\n",
    "from snowflake.snowpark import Session\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "session = Session.builder.configs(SnowflakeLoginOptions(\"connection_name\")).create()\n",
    "reg = registry.Registry(session=session, database_name='rajiv', schema_name='demos')\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2530619",
   "metadata": {},
   "source": [
    "### Run Predictions Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11df29bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure encoding time for random sentences\n",
    "start_time = time.time()\n",
    "embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to encode {num_sentences} sentences using Local Model: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002642e8-4f0e-4810-939f-13690ae27ce4",
   "metadata": {
    "collapsed": false,
    "name": "cell31"
   },
   "source": [
    "### Run Predictions in Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b63eb7-da66-482a-9573-9c2a621a3de3",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell29"
   },
   "outputs": [],
   "source": [
    "# Log the model with conda dependencies for warehouses\n",
    "conda_forge_model = reg.log_model(\n",
    "    model,\n",
    "    model_name=\"sentence_transformer_minilm\",\n",
    "    version_name='conda_forge_force',\n",
    "    sample_input_data=sentences,  # Needed for determining signature of the model\n",
    "   conda_dependencies=[\"sentence-transformers\", \"pytorch\", \"transformers\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31409c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure encoding time for random sentences\n",
    "conda_model = reg.get_model(\"sentence_transformer_minilm\").version(\"conda_forge_force\")\n",
    "start_time = time.time()\n",
    "conda_model.run(sentences, function_name=\"encode\")\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to encode {num_sentences} sentences using Warehouse: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d4b4e1",
   "metadata": {},
   "source": [
    "### Run Predictions in SPSC Container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ed5dcf",
   "metadata": {},
   "source": [
    "This process first generates the container and then runs the predictions in the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e47506e-5252-4ac4-98c3-7532505fffff",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell27"
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Log the model with pip dependencies for containers\n",
    "pip_model = reg.log_model(\n",
    "    model,\n",
    "    model_name=\"sentence_transformer_minilm\",\n",
    "    version_name='pip',\n",
    "    sample_input_data=sentences,  # Needed for determining signature of the model\n",
    "   pip_requirements=[\"sentence-transformers\", \"torch\", \"transformers\"], # If you want to run this model in the Warehouse, you can use conda_dependencies instead\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_model = reg.get_model(\"sentence_transformer_minilm\").version(\"pip\")\n",
    "pip_model.create_service(service_name=\"sentence_transformer_minilmV2\",\n",
    "                  service_compute_pool=\"NOTEBOOK_GPU_NV_S\",\n",
    "                  image_repo=\"rajiv.public.images\",\n",
    "                  build_external_access_integration=\"RAJ_OPEN_ACCESS_INTEGRATION\",\n",
    "                  gpu_requests=\"1\",\n",
    "                  ingress_enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a32e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure encoding time for random sentences\n",
    "start_time = time.time()\n",
    "spcs_prediction = pip_model.run(sentences, function_name='encode', service_name=\"sentence_transformer_minilmV2\")\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to encode {num_sentences} sentences using Deploy: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb6f05-314d-4676-b26e-6045d2af6c9c",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell43"
   },
   "outputs": [],
   "source": [
    "session.sql(\"DROP SERVICE RAJIV.DEMOS.sentence_transformer_minilmV2\").collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "working311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
