{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc3f8c-5fe5-4ff1-b27f-d54abf7a5716",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d6540c-7e50-4b67-a55e-209538e8531e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "num_rows = 500000\n",
    "num_numerical_cols = 40\n",
    "num_categorical_cols = 10\n",
    "num_classes = 2  # for the target variable\n",
    "\n",
    "# Generating numerical data\n",
    "numerical_data = np.random.randn(num_rows, num_numerical_cols)\n",
    "\n",
    "# Generating categorical data\n",
    "categorical_data = np.random.choice(['A', 'B', 'C', 'D','E','F','G','H','I','J','K'], size=(num_rows, num_categorical_cols))\n",
    "\n",
    "# Combining into a DataFrame\n",
    "column_names = [f'num_col_{i+1}' for i in range(num_numerical_cols)] + [f'cat_col_{i+1}' for i in range(num_categorical_cols)]\n",
    "data = pd.DataFrame(np.hstack((numerical_data, categorical_data)), columns=column_names)\n",
    "\n",
    "# Generating a target variable\n",
    "data['target'] = np.random.choice(range(num_classes), num_rows)\n",
    "\n",
    "# Display dataset summary\n",
    "print(data.head())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ac3ea2-4d0f-4e3c-9f28-916033a1b643",
   "metadata": {
    "collapsed": false,
    "name": "cell2"
   },
   "source": [
    "### Local Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a73a01-dc93-4480-9276-75c993be86e4",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "snowpark_df = session.table(\"TPCDS_XGBOOST.DEMO.XGBOOST500k\")\n",
    "data = snowpark_df.to_pandas()\n",
    "\n",
    "# Assume data is your DataFrame\n",
    "X = data.drop('TARGET', axis=1)\n",
    "y = data['TARGET']\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747fcb60-6463-41b0-9b32-33b3827b9b4f",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell25"
   },
   "outputs": [],
   "source": [
    "# Define the XGBoost model\n",
    "#xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "#xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', tree_method=\"hist\", predictor= \"cpu_predictor\")\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', tree_method=\"gpu_hist\", predictor= \"gpu_predictor\")\n",
    "\n",
    "\n",
    "# Create a pipeline that first preprocesses the data and then fits the model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', xgb_model)\n",
    "])\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5303d509-cfe5-4e50-9cfb-81fc251fe035",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell23"
   },
   "outputs": [],
   "source": [
    "X_train.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804af4f5-8ef0-4f40-ba50-38bd53bea107",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d741e5e4-dcd6-4f4c-96d8-41e99b650bc8",
   "metadata": {
    "collapsed": false,
    "name": "cell19"
   },
   "source": [
    "### Snowpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e601ee61-3d96-47fe-95ea-df2a6fa343fc",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30ee7c-a135-4078-b5a8-c1b6b04bdc89",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell17"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import col\n",
    "from snowflake.snowpark.types import StringType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.ml.modeling.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from snowflake.ml.modeling.impute import SimpleImputer\n",
    "\n",
    "from snowflake.ml.modeling.compose import ColumnTransformer\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "from snowflake.ml.modeling.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from snowflake.ml.modeling.impute import SimpleImputer\n",
    "from snowflake.ml.modeling.model_selection import GridSearchCV\n",
    "import re\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "#data.columns = data.columns.str.upper()\n",
    "#input_df = session.create_dataframe(data)\n",
    "#cols = input_df.columns\n",
    "#for old_col in cols:\n",
    "#    new_col = re.sub(r'[^a-zA-Z0-9_]', '', old_col)\n",
    "#    new_col = new_col.upper()\n",
    "#    input_df = input_df.rename(F.col(old_col), new_col)\n",
    "\n",
    "\n",
    "\n",
    "#input_df.write.mode('overwrite').save_as_table('TPCDS_XGBOOST.DEMO.XGBOOST100k')\n",
    "\n",
    "# Load the data from a Snowflake table\n",
    "snowpark_df = session.table(\"TPCDS_XGBOOST.DEMO.XGBOOST500k\")\n",
    "snowdf_train, snowdf_test = snowpark_df.random_split([0.8, 0.2], seed=82)\n",
    "#feature_cols = snowpark_df.columns\n",
    "#feature_cols.remove(\"TARGET\")\n",
    "target_col = [\"TARGET\"]\n",
    "\n",
    "# Select numerical and categorical columns\n",
    "numerical_cols = [\n",
    "    \"NUM_COL_1\", \"NUM_COL_2\", \"NUM_COL_3\", \"NUM_COL_4\", \"NUM_COL_5\", \"NUM_COL_6\", \"NUM_COL_7\", \"NUM_COL_8\", \n",
    "    \"NUM_COL_9\", \"NUM_COL_10\", \"NUM_COL_11\", \"NUM_COL_12\", \"NUM_COL_13\", \"NUM_COL_14\", \"NUM_COL_15\", \n",
    "    \"NUM_COL_16\", \"NUM_COL_17\", \"NUM_COL_18\", \"NUM_COL_19\", \"NUM_COL_20\", \"NUM_COL_21\", \"NUM_COL_22\", \n",
    "    \"NUM_COL_23\", \"NUM_COL_24\", \"NUM_COL_25\", \"NUM_COL_26\", \"NUM_COL_27\", \"NUM_COL_28\", \"NUM_COL_29\", \n",
    "    \"NUM_COL_30\", \"NUM_COL_31\", \"NUM_COL_32\", \"NUM_COL_33\", \"NUM_COL_34\", \"NUM_COL_35\", \"NUM_COL_36\", \n",
    "    \"NUM_COL_37\", \"NUM_COL_38\", \"NUM_COL_39\", \"NUM_COL_40\"\n",
    "]\n",
    "\n",
    "categorical_cols = [\n",
    "    \"CAT_COL_1\", \"CAT_COL_2\", \"CAT_COL_3\", \"CAT_COL_4\", \"CAT_COL_5\", \"CAT_COL_6\", \n",
    "    \"CAT_COL_7\", \"CAT_COL_8\", \"CAT_COL_9\", \"CAT_COL_10\"\n",
    "]\n",
    "\n",
    "for col_name in numerical_cols:\n",
    "    snowdf_train = snowdf_train.with_column(col_name, col(col_name).cast(\"FLOAT\"))\n",
    "\n",
    "pipeline = Pipeline(\n",
    "            steps=[\n",
    "                (\"OHE\", OneHotEncoder(input_cols=categorical_cols, output_cols=categorical_cols, drop_input_cols=True, handle_unknown='ignore')),\n",
    "                (\"MMS\", MinMaxScaler(clip=True, input_cols=numerical_cols, output_cols=numerical_cols)),\n",
    "                (\"SS\", StandardScaler(input_cols=numerical_cols, output_cols=numerical_cols)),\n",
    "               # (\"classifier\", XGBClassifier(label_cols=target_col,tree_method=\"hist\", predictor= \"cpu_predictor\")),\n",
    "               # (\"classifier\", XGBClassifier(label_cols=target_col,tree_method=\"gpu_hist\", predictor= \"gpu_predictor\")),\n",
    "                (\"classifier\", XGBClassifier(label_cols=target_col)),\n",
    "            ]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb11410-7a59-47a6-816a-53f43362e6d0",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell21"
   },
   "outputs": [],
   "source": [
    "snowdf_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208346dd-f07c-45c9-a0fd-97719b5946e7",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell26"
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred1 = pipeline.fit_predict(snowdf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185d134b-c087-44b4-b127-04bb84294f21",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.modeling.metrics import accuracy_score\n",
    "\n",
    "# Fit the model\n",
    "#pipeline.fit(snowdf_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.fit_predict(snowdf_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572d175-01e6-4c56-930e-f473b1b02388",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell24"
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f528308a-dc98-4ed4-b745-61f8bd58a381",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell18"
   },
   "outputs": [],
   "source": [
    "xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4deda26-be90-4e2c-bbec-617de9cdd3d2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = pipeline.predict(snowdf_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
