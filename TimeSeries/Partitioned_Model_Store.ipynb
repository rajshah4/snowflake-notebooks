{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2452b045-2bcc-4df1-bfdf-6888c8320ed5",
   "metadata": {},
   "source": [
    "# Partitioned Custom ML Model with Model Registry\n",
    "\n",
    "This notebook includes two different models and datasets. They are both capable of being tested locally as well as run entirely in Snowflake. I have also made it so you can push the datasets into a Snowflake table for running the inference from the Snowflake model registry.\n",
    "\n",
    "### Partitioned restaurant traffic forecasting model\n",
    "\n",
    "The dataset is loaded locally from the `Partitioned_Custom_Model_Restaurant_Traffic_Data.csv` file.\n",
    "\n",
    "Change `\"MY_DB\"` and `\"MY_SCHEMA\"` to your desired existing database and schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28a2c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from snowflake.snowpark import Session\n",
    "from cryptography.hazmat.primitives import serialization\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "\n",
    "with open('../../creds.json') as f:\n",
    "    data = json.load(f)\n",
    "    USERNAME = data['user']\n",
    "    SF_ACCOUNT = data['account']\n",
    "    SF_WH = data['warehouse']\n",
    "    passphrase = data['passphrase']\n",
    "\n",
    "# Read the private key from the .p8 file\n",
    "with open('../../rsa_key.p8', 'rb') as key_file:\n",
    "    private_key = key_file.read()\n",
    "\n",
    "# If the private key is encrypted, load it with a passphrase\n",
    "# Replace 'your_key_passphrase' with your actual passphrase if needed\n",
    "private_key_obj = serialization.load_pem_private_key(\n",
    "    private_key,\n",
    "    password=passphrase.encode() if passphrase else None,\n",
    "    backend=default_backend()\n",
    ")\n",
    "\n",
    "# Define connection parameters including the private key\n",
    "CONNECTION_PARAMETERS = {\n",
    "    'user': USERNAME,\n",
    "    'account': SF_ACCOUNT,\n",
    "    'private_key': private_key_obj,\n",
    "    'warehouse': SF_WH,\n",
    "}\n",
    "\n",
    "# Create a session with the specified connection parameters\n",
    "session = Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "\n",
    "from snowflake.core.warehouse import Warehouse\n",
    "from snowflake.core import Root\n",
    "root = Root(session)\n",
    "from snowflake.snowpark.functions import col \n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e3b1e3f-fc07-4598-955b-063bbcb93efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from snowflake.ml.model import custom_model\n",
    "from snowflake.ml.model import model_signature\n",
    "from snowflake.ml.registry import registry\n",
    "from snowflake.ml.utils.connection_params import SnowflakeLoginOptions\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a437716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User                        : RSHAH\n",
      "Role                        : \"RAJIV\"\n",
      "Database                    : \"RAJIV\"\n",
      "Schema                      : \"PUBLIC\"\n",
      "Warehouse                   : \"RAJIV\"\n",
      "Snowflake version           : 8.34.0\n",
      "Snowpark for Python version : 1.20.0\n",
      "Snowflake ML version        : 1.6.1\n"
     ]
    }
   ],
   "source": [
    "from snowflake.snowpark.version import VERSION\n",
    "snowflake_environment = session.sql('select current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "from snowflake.ml import version\n",
    "mlversion = version.VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(session.get_current_role()))\n",
    "print('Database                    : {}'.format(session.get_current_database()))\n",
    "print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))\n",
    "print('Snowflake ML version        : {}.{}.{}'.format(mlversion[0],mlversion[2],mlversion[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4d5a9dd-a700-4de2-8065-4308678fd917",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTRY_DATABASE_NAME = \"TPCDS_XGBOOST\"\n",
    "REGISTRY_SCHEMA_NAME = \"DEMO\"\n",
    "reg = registry.Registry(session=session, database_name=REGISTRY_DATABASE_NAME, schema_name=REGISTRY_SCHEMA_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f78f580-67a0-4cce-b44e-f7c8424f9b43",
   "metadata": {},
   "source": [
    "#### The dataset contains an epoch timestamp in milliseconds, a store ID which will later be used as a partition column, a feature column `COLLEGE_TOWN`, and a target to be forecasted, `HOURLY_TRAFFIC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0a2387e2-0c09-4a56-893b-85d64e3f2657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "|\"EPOCH\"          |\"STORE_ID\"  |\"COLLEGE_TOWN\"  |\"HOURLY_TRAFFIC\"  |\n",
      "--------------------------------------------------------------------\n",
      "|1529154000000.0  |1.0         |1.0             |82                |\n",
      "|1529182800000.0  |1.0         |1.0             |2                 |\n",
      "|1529247600000.0  |1.0         |1.0             |35                |\n",
      "|1529269200000.0  |1.0         |1.0             |9                 |\n",
      "|1529326800000.0  |1.0         |1.0             |114               |\n",
      "|1529514000000.0  |1.0         |1.0             |24                |\n",
      "|1529697600000.0  |1.0         |1.0             |31                |\n",
      "|1529424000000.0  |1.0         |1.0             |28                |\n",
      "|1529575200000.0  |1.0         |1.0             |13                |\n",
      "|1529931600000.0  |1.0         |1.0             |110               |\n",
      "--------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data from csv file into pandas dataframe.\n",
    "test_df_pandas = pd.read_csv(\"Partitioned_Custom_Model_Restaurant_Traffic_Data.csv\")\n",
    "test_df = session.create_dataframe(test_df_pandas)\n",
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09535059",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.write.mode('overwrite').save_as_table('TPCDS_XGBOOST.DEMO.Restaurant_Traffic_Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be53e6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94388048",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8e284ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = session.table('TPCDS_XGBOOST.DEMO.Restaurant_Traffic_Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca3e762",
   "metadata": {},
   "source": [
    "Data set is \n",
    "5209585 rows with 200 unique store IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4961289a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "|\"EPOCH\"          |\"STORE_ID\"  |\"COLLEGE_TOWN\"  |\"HOURLY_TRAFFIC\"  |\n",
      "--------------------------------------------------------------------\n",
      "|1652713200000.0  |49.0        |1.0             |65                |\n",
      "|1652806800000.0  |49.0        |1.0             |32                |\n",
      "|1652882400000.0  |49.0        |1.0             |17                |\n",
      "|1652907600000.0  |49.0        |1.0             |7                 |\n",
      "|1653066000000.0  |49.0        |1.0             |31                |\n",
      "|1653127200000.0  |49.0        |1.0             |60                |\n",
      "|1653145200000.0  |49.0        |1.0             |41                |\n",
      "|1653217200000.0  |49.0        |1.0             |98                |\n",
      "|1653220800000.0  |49.0        |1.0             |101               |\n",
      "|1653224400000.0  |49.0        |1.0             |100               |\n",
      "--------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "96b31eb8-d9c3-4257-993c-4544ddb7a14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    }
   ],
   "source": [
    "unique_store_count = test_df.select(test_df['STORE_ID']).distinct().count()\n",
    "print(unique_store_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7decef9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5209585"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "182ba1e0-370f-4cc8-86c4-dec4fc9f153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecastingModel(custom_model.CustomModel):\n",
    "\n",
    "    # Use the same decorator as for methods with FUNCTION inference.\n",
    "    @custom_model.partitioned_inference_api\n",
    "    def predict(self, df: pd.DataFrame) -> pd.DataFrame:        \n",
    "        import xgboost\n",
    "\n",
    "        # Set the time column as our index.\n",
    "        input_df = df.set_index('EPOCH')\n",
    "        input_df.index = pd.to_datetime(df['EPOCH'], unit='ms')\n",
    "\n",
    "        # Generate categorical features using the datetime index.\n",
    "        input_df['HOUR'] = input_df.index.hour.astype(\"category\")\n",
    "        input_df['DAY_OF_WEEK'] = input_df.index.dayofweek.astype(\"category\")\n",
    "        input_df['MONTH'] = input_df.index.month.astype(\"category\")\n",
    "        input_df['YEAR'] = input_df.index.year.astype(\"category\")\n",
    "        \n",
    "        input_df['COLLEGE_TOWN'] = input_df['COLLEGE_TOWN'].astype(\"category\")\n",
    "        \n",
    "        # Use get_dummies (one-hot encoding) for categorical features.\n",
    "        final = pd.get_dummies(data=input_df, columns=['COLLEGE_TOWN', 'HOUR', 'MONTH', 'YEAR', 'DAY_OF_WEEK'])\n",
    "\n",
    "        # Define the train & forecast split thresholds.\n",
    "        today = pd.to_datetime('2022-10-01')\n",
    "        yesterday = today - timedelta(days=1)\n",
    "        four_weeks = today + timedelta(days=28)\n",
    "        tomorrow = today + timedelta(days=1)\n",
    "\n",
    "        # Train data starts on June 16th 2018 and ends on September 30th.\n",
    "        train = final[(final.index >= pd.to_datetime('16-Jun-2018')) & (final.index <= pd.to_datetime(yesterday))]\n",
    "        \n",
    "        # The forecast starts from October 1st 2022 and goes 4 weeks into the future.\n",
    "        forecast = final[(final.index >= pd.to_datetime(tomorrow)) & (final.index <= pd.to_datetime(four_weeks))]\n",
    "\n",
    "        # Remove the target from the input dataset, and construct target dataset.\n",
    "        X_train = train.drop('HOURLY_TRAFFIC', axis=1)\n",
    "        y_train = train['HOURLY_TRAFFIC']\n",
    "\n",
    "        X_forecast = forecast.drop('HOURLY_TRAFFIC', axis=1)\n",
    "        \n",
    "        # Train an XGBoost regression model.\n",
    "        model = xgboost.XGBRegressor(n_estimators=200, n_jobs=1)\n",
    "        model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "        # Predict the hourly forecast for the future dates and make sure no predictions are less than zero.\n",
    "        forecast['PREDICTION'] = model.predict(X_forecast)\n",
    "        forecast['EPOCH_OUT'] = [t.value // 10**9 for t in forecast.index]\n",
    "        forecast = forecast[['EPOCH_OUT', 'PREDICTION']]\n",
    "        forecast = forecast.sort_index()\n",
    "        forecast.loc[forecast['PREDICTION'] < 0, 'PREDICTION'] = 0\n",
    "\n",
    "        return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "386252c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = reg.get_model(\"forecast\").version(\"v13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "58fadf9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPOCH_OUT</th>\n",
       "      <th>PREDICTION</th>\n",
       "      <th>STORE_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.664694e+09</td>\n",
       "      <td>77.348640</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.664698e+09</td>\n",
       "      <td>76.391113</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.664701e+09</td>\n",
       "      <td>75.288567</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.664705e+09</td>\n",
       "      <td>77.084717</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.664708e+09</td>\n",
       "      <td>96.338638</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86395</th>\n",
       "      <td>1.666980e+09</td>\n",
       "      <td>31.088211</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86396</th>\n",
       "      <td>1.666984e+09</td>\n",
       "      <td>30.569330</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86397</th>\n",
       "      <td>1.666987e+09</td>\n",
       "      <td>32.221611</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86398</th>\n",
       "      <td>1.666991e+09</td>\n",
       "      <td>6.004010</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86399</th>\n",
       "      <td>1.666994e+09</td>\n",
       "      <td>5.023667</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          EPOCH_OUT  PREDICTION  STORE_ID\n",
       "0      1.664694e+09   77.348640     182.0\n",
       "1      1.664698e+09   76.391113     182.0\n",
       "2      1.664701e+09   75.288567     182.0\n",
       "3      1.664705e+09   77.084717     182.0\n",
       "4      1.664708e+09   96.338638     182.0\n",
       "...             ...         ...       ...\n",
       "86395  1.666980e+09   31.088211      78.0\n",
       "86396  1.666984e+09   30.569330      78.0\n",
       "86397  1.666987e+09   32.221611      78.0\n",
       "86398  1.666991e+09    6.004010      78.0\n",
       "86399  1.666994e+09    5.023667      78.0\n",
       "\n",
       "[86400 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = mv.run(test_df, partition_column=\"STORE_ID\")\n",
    "result.select(\"EPOCH_OUT\", \"PREDICTION\", \"STORE_ID\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8a8534f9-71db-4319-be58-5a9ff3f2fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_forecasting_model = ForecastingModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db5be5-6816-492d-991a-144a32d922ae",
   "metadata": {},
   "source": [
    "#### The predict method can be tested locally by using a pandas dataframe directly. Here we can run `predict` for a single partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0519cb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/f1b0hx_54t70j1szv_9_kt0c0000gn/T/ipykernel_59767/2495542525.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  forecast['PREDICTION'] = model.predict(X_forecast)\n",
      "/var/folders/wh/f1b0hx_54t70j1szv_9_kt0c0000gn/T/ipykernel_59767/2495542525.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  forecast['EPOCH_OUT'] = [t.value // 10**9 for t in forecast.index]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPOCH_OUT</th>\n",
       "      <th>PREDICTION</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPOCH</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-10-02 07:00:00</th>\n",
       "      <td>1664694000</td>\n",
       "      <td>77.787636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-02 08:00:00</th>\n",
       "      <td>1664697600</td>\n",
       "      <td>76.995056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-02 09:00:00</th>\n",
       "      <td>1664701200</td>\n",
       "      <td>76.751877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-02 10:00:00</th>\n",
       "      <td>1664704800</td>\n",
       "      <td>76.600456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-02 11:00:00</th>\n",
       "      <td>1664708400</td>\n",
       "      <td>96.709358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28 18:00:00</th>\n",
       "      <td>1666980000</td>\n",
       "      <td>30.727842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28 19:00:00</th>\n",
       "      <td>1666983600</td>\n",
       "      <td>30.608843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28 20:00:00</th>\n",
       "      <td>1666987200</td>\n",
       "      <td>31.198336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28 21:00:00</th>\n",
       "      <td>1666990800</td>\n",
       "      <td>4.420763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28 22:00:00</th>\n",
       "      <td>1666994400</td>\n",
       "      <td>4.459415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>432 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      EPOCH_OUT  PREDICTION\n",
       "EPOCH                                      \n",
       "2022-10-02 07:00:00  1664694000   77.787636\n",
       "2022-10-02 08:00:00  1664697600   76.995056\n",
       "2022-10-02 09:00:00  1664701200   76.751877\n",
       "2022-10-02 10:00:00  1664704800   76.600456\n",
       "2022-10-02 11:00:00  1664708400   96.709358\n",
       "...                         ...         ...\n",
       "2022-10-28 18:00:00  1666980000   30.727842\n",
       "2022-10-28 19:00:00  1666983600   30.608843\n",
       "2022-10-28 20:00:00  1666987200   31.198336\n",
       "2022-10-28 21:00:00  1666990800    4.420763\n",
       "2022-10-28 22:00:00  1666994400    4.459415\n",
       "\n",
       "[432 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_forecasting_model.predict(df1.loc[df1['STORE_ID'] == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c703566",
   "metadata": {},
   "source": [
    "## Test this all in pandas locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "154f3da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPOCH</th>\n",
       "      <th>STORE_ID</th>\n",
       "      <th>COLLEGE_TOWN</th>\n",
       "      <th>HOURLY_TRAFFIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.209584e+06</td>\n",
       "      <td>5.209584e+06</td>\n",
       "      <td>5209584.0</td>\n",
       "      <td>5.209585e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.599444e+12</td>\n",
       "      <td>1.005000e+02</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.150246e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.060217e+10</td>\n",
       "      <td>5.773434e+01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.016415e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.529132e+12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.564265e+12</td>\n",
       "      <td>5.075000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.700000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.599430e+12</td>\n",
       "      <td>1.005000e+02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.634594e+12</td>\n",
       "      <td>1.510000e+02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.669673e+12</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.320000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              EPOCH      STORE_ID  COLLEGE_TOWN  HOURLY_TRAFFIC\n",
       "count  5.209584e+06  5.209584e+06     5209584.0    5.209585e+06\n",
       "mean   1.599444e+12  1.005000e+02           0.5    4.150246e+01\n",
       "std    4.060217e+10  5.773434e+01           0.5    3.016415e+01\n",
       "min    1.529132e+12  1.000000e+00           0.0    0.000000e+00\n",
       "25%    1.564265e+12  5.075000e+01           0.0    1.700000e+01\n",
       "50%    1.599430e+12  1.005000e+02           1.0    3.100000e+01\n",
       "75%    1.634594e+12  1.510000e+02           1.0    6.500000e+01\n",
       "max    1.669673e+12  2.000000e+02           1.0    1.320000e+02"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = test_df.to_pandas()\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eedcaa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e57cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import xgboost\n",
    "\n",
    "# Assuming ForecastingModel is your custom class\n",
    "class ForecastingModel(custom_model.CustomModel):\n",
    "    \n",
    "    @custom_model.partitioned_inference_api\n",
    "    def predict(self, df: pd.DataFrame) -> pd.DataFrame:        \n",
    "        # Prediction logic from your current model...\n",
    "        input_df = df.set_index('EPOCH')\n",
    "        input_df.index = pd.to_datetime(df['EPOCH'], unit='ms')\n",
    "        input_df['HOUR'] = input_df.index.hour.astype(\"category\")\n",
    "        input_df['DAY_OF_WEEK'] = input_df.index.dayofweek.astype(\"category\")\n",
    "        input_df['MONTH'] = input_df.index.month.astype(\"category\")\n",
    "        input_df['YEAR'] = input_df.index.year.astype(\"category\")\n",
    "        input_df['COLLEGE_TOWN'] = input_df['COLLEGE_TOWN'].astype(\"category\")\n",
    "        final = pd.get_dummies(data=input_df, columns=['COLLEGE_TOWN', 'HOUR', 'MONTH', 'YEAR', 'DAY_OF_WEEK'])\n",
    "\n",
    "        today = pd.to_datetime('2022-10-01')\n",
    "        yesterday = today - timedelta(days=1)\n",
    "        four_weeks = today + timedelta(days=28)\n",
    "        tomorrow = today + timedelta(days=1)\n",
    "        train = final[(final.index >= pd.to_datetime('16-Jun-2018')) & (final.index <= pd.to_datetime(yesterday))]\n",
    "        forecast = final[(final.index >= pd.to_datetime(tomorrow)) & (final.index <= pd.to_datetime(four_weeks))]\n",
    "\n",
    "        X_train = train.drop('HOURLY_TRAFFIC', axis=1)\n",
    "        y_train = train['HOURLY_TRAFFIC']\n",
    "        X_forecast = forecast.drop('HOURLY_TRAFFIC', axis=1)\n",
    "\n",
    "        model = xgboost.XGBRegressor(n_estimators=200, n_jobs=1)\n",
    "        model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "        forecast['PREDICTION'] = model.predict(X_forecast)\n",
    "        forecast['EPOCH_OUT'] = [t.value // 10**9 for t in forecast.index]\n",
    "        forecast = forecast[['EPOCH_OUT', 'PREDICTION']]\n",
    "        forecast.loc[forecast['PREDICTION'] < 0, 'PREDICTION'] = 0\n",
    "\n",
    "        return forecast\n",
    "\n",
    "# Function to parallelize\n",
    "def parallel_predict(store_data, model):\n",
    "    return model.predict(store_data)\n",
    "\n",
    "# Assuming df1 is your complete dataset\n",
    "store_groups = [group for _, group in df1.groupby('STORE_ID')]\n",
    "\n",
    "# Initialize the ForecastingModel\n",
    "model = ForecastingModel()\n",
    "\n",
    "# Parallel execution using Joblib\n",
    "num_cores = -1  # Use all available cores\n",
    "results = Parallel(n_jobs=num_cores)(delayed(parallel_predict)(store_data, model) for store_data in store_groups)\n",
    "\n",
    "# Combine or process the results as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656b0b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"function_type\": \"TABLE_FUNCTION\",\n",
    "}\n",
    "\n",
    "mv = reg.log_model(\n",
    "    my_forecasting_model,\n",
    "    model_name=\"forecast\",\n",
    "    version_name=\"v13\",\n",
    "    conda_dependencies=[\"pandas\", \"scikit-learn\", \"xgboost\"],\n",
    "    options=options,\n",
    "    signatures={\n",
    "        \"predict\": model_signature.ModelSignature(\n",
    "            inputs=[\n",
    "                model_signature.FeatureSpec(name=\"EPOCH\", dtype=model_signature.DataType.DOUBLE),\n",
    "                model_signature.FeatureSpec(name=\"STORE_ID\", dtype=model_signature.DataType.DOUBLE),\n",
    "                model_signature.FeatureSpec(name=\"COLLEGE_TOWN\", dtype=model_signature.DataType.DOUBLE),\n",
    "                model_signature.FeatureSpec(name=\"HOURLY_TRAFFIC\", dtype=model_signature.DataType.INT64),\n",
    "            ],\n",
    "            outputs=[\n",
    "                model_signature.FeatureSpec(name=\"EPOCH_OUT\", dtype=model_signature.DataType.FLOAT),\n",
    "                model_signature.FeatureSpec(name=\"PREDICTION\", dtype=model_signature.DataType.FLOAT),\n",
    "            ],\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a664ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3b11059-8d8f-4023-a3a8-feaab66bd595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/f1b0hx_54t70j1szv_9_kt0c0000gn/T/ipykernel_29643/2495542525.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  forecast['PREDICTION'] = model.predict(X_forecast)\n",
      "/var/folders/wh/f1b0hx_54t70j1szv_9_kt0c0000gn/T/ipykernel_29643/2495542525.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  forecast['EPOCH_OUT'] = [t.value // 10**9 for t in forecast.index]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPOCH_OUT</th>\n",
       "      <th>PREDICTION</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPOCH</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-10-02 07:00:00</th>\n",
       "      <td>1664694000</td>\n",
       "      <td>77.787636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-02 08:00:00</th>\n",
       "      <td>1664697600</td>\n",
       "      <td>76.995056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-02 09:00:00</th>\n",
       "      <td>1664701200</td>\n",
       "      <td>76.751877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-02 10:00:00</th>\n",
       "      <td>1664704800</td>\n",
       "      <td>76.600456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-02 11:00:00</th>\n",
       "      <td>1664708400</td>\n",
       "      <td>96.709358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28 18:00:00</th>\n",
       "      <td>1666980000</td>\n",
       "      <td>30.727842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28 19:00:00</th>\n",
       "      <td>1666983600</td>\n",
       "      <td>30.608843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28 20:00:00</th>\n",
       "      <td>1666987200</td>\n",
       "      <td>31.198336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28 21:00:00</th>\n",
       "      <td>1666990800</td>\n",
       "      <td>4.420763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28 22:00:00</th>\n",
       "      <td>1666994400</td>\n",
       "      <td>4.459415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>432 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      EPOCH_OUT  PREDICTION\n",
       "EPOCH                                      \n",
       "2022-10-02 07:00:00  1664694000   77.787636\n",
       "2022-10-02 08:00:00  1664697600   76.995056\n",
       "2022-10-02 09:00:00  1664701200   76.751877\n",
       "2022-10-02 10:00:00  1664704800   76.600456\n",
       "2022-10-02 11:00:00  1664708400   96.709358\n",
       "...                         ...         ...\n",
       "2022-10-28 18:00:00  1666980000   30.727842\n",
       "2022-10-28 19:00:00  1666983600   30.608843\n",
       "2022-10-28 20:00:00  1666987200   31.198336\n",
       "2022-10-28 21:00:00  1666990800    4.420763\n",
       "2022-10-28 22:00:00  1666994400    4.459415\n",
       "\n",
       "[432 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_forecasting_model.predict(test_df_pandas.loc[test_df_pandas['STORE_ID'] == 1])\n",
    "#my_forecasting_model.predict(test_df_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ad2585-c013-4730-b617-b2336d176479",
   "metadata": {},
   "source": [
    "#### Log the model, specifying the `function_type: \"TABLE_FUNCTION\"` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e77f15-ae88-42fc-b6d3-e21665cd6fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"function_type\": \"TABLE_FUNCTION\",\n",
    "}\n",
    "\n",
    "mv = reg.log_model(\n",
    "    my_forecasting_model,\n",
    "    model_name=\"forecast\",\n",
    "    version_name=\"v13\",\n",
    "    conda_dependencies=[\"pandas\", \"scikit-learn\", \"xgboost\"],\n",
    "    options=options,\n",
    "    signatures={\n",
    "        \"predict\": model_signature.ModelSignature(\n",
    "            inputs=[\n",
    "                model_signature.FeatureSpec(name=\"EPOCH\", dtype=model_signature.DataType.DOUBLE),\n",
    "                model_signature.FeatureSpec(name=\"STORE_ID\", dtype=model_signature.DataType.DOUBLE),\n",
    "                model_signature.FeatureSpec(name=\"COLLEGE_TOWN\", dtype=model_signature.DataType.DOUBLE),\n",
    "                model_signature.FeatureSpec(name=\"HOURLY_TRAFFIC\", dtype=model_signature.DataType.INT64),\n",
    "            ],\n",
    "            outputs=[\n",
    "                model_signature.FeatureSpec(name=\"EPOCH_OUT\", dtype=model_signature.DataType.FLOAT),\n",
    "                model_signature.FeatureSpec(name=\"PREDICTION\", dtype=model_signature.DataType.FLOAT),\n",
    "            ],\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fcde38-5b9d-4b96-8833-f699611c643b",
   "metadata": {},
   "source": [
    "#### Use the `run` method for inference, specifying the partition column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a16f831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"SNOWPARK_OPT_WH\"\n"
     ]
    }
   ],
   "source": [
    "snowpark_opt_wh = Warehouse(\n",
    "  name=\"snowpark_opt_wh\",\n",
    "  warehouse_size=\"MEDIUM\",\n",
    "  warehouse_type = \"SNOWPARK-OPTIMIZED\",\n",
    "  auto_suspend=600,\n",
    ")\n",
    "warehouses = root.warehouses[\"snowpark_opt_wh\"]\n",
    "warehouses.create_or_alter(snowpark_opt_wh)\n",
    "\n",
    "session.sql('USE WAREHOUSE SNOWPARK_OPT_WH').collect()\n",
    "#session.sql('alter session set USE_CACHED_RESULT = FALSE').collect()\n",
    "#session.sql('alter session set query_tag = \"TS_XG_LARGE\" ').collect()\n",
    "print(session.get_current_warehouse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37a970ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = reg.get_model(\"forecast\").version(\"v13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53dda197-3afd-47a3-9fd6-d1237af6804f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPOCH_OUT</th>\n",
       "      <th>PREDICTION</th>\n",
       "      <th>STORE_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.664694e+09</td>\n",
       "      <td>77.348640</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.664698e+09</td>\n",
       "      <td>76.391113</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.664701e+09</td>\n",
       "      <td>75.288567</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.664705e+09</td>\n",
       "      <td>77.084717</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.664708e+09</td>\n",
       "      <td>96.338638</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86395</th>\n",
       "      <td>1.666980e+09</td>\n",
       "      <td>31.088211</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86396</th>\n",
       "      <td>1.666984e+09</td>\n",
       "      <td>30.569330</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86397</th>\n",
       "      <td>1.666987e+09</td>\n",
       "      <td>32.221611</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86398</th>\n",
       "      <td>1.666991e+09</td>\n",
       "      <td>6.004010</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86399</th>\n",
       "      <td>1.666994e+09</td>\n",
       "      <td>5.023667</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          EPOCH_OUT  PREDICTION  STORE_ID\n",
       "0      1.664694e+09   77.348640     182.0\n",
       "1      1.664698e+09   76.391113     182.0\n",
       "2      1.664701e+09   75.288567     182.0\n",
       "3      1.664705e+09   77.084717     182.0\n",
       "4      1.664708e+09   96.338638     182.0\n",
       "...             ...         ...       ...\n",
       "86395  1.666980e+09   31.088211      78.0\n",
       "86396  1.666984e+09   30.569330      78.0\n",
       "86397  1.666987e+09   32.221611      78.0\n",
       "86398  1.666991e+09    6.004010      78.0\n",
       "86399  1.666994e+09    5.023667      78.0\n",
       "\n",
       "[86400 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = mv.run(test_df, partition_column=\"STORE_ID\")\n",
    "result.select(\"EPOCH_OUT\", \"PREDICTION\", \"STORE_ID\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fc0df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimized S it ran in 24 seconds \n",
    "## Optimized M is ran in 21 seconds \n",
    "\n",
    "\n",
    "Raj test:\n",
    "## Optimized L ran in 15 seconds\n",
    "\n",
    "## Local test - one thread it ran in 1 minute 40 seconds\n",
    "## Local test - entire dataset took 4 minutes 30 seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1593065f",
   "metadata": {},
   "source": [
    "## StatsForecast Arima Model on Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "35ae7869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>0.046169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>1.093130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2.172780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>3.198384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>4.269408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2001-05-08</td>\n",
       "      <td>6.136047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2001-05-09</td>\n",
       "      <td>0.476046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2001-05-10</td>\n",
       "      <td>1.334887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2001-05-11</td>\n",
       "      <td>2.333404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2001-05-12</td>\n",
       "      <td>3.005552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3007 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds         y\n",
       "unique_id                     \n",
       "0         2000-01-01  0.046169\n",
       "0         2000-01-02  1.093130\n",
       "0         2000-01-03  2.172780\n",
       "0         2000-01-04  3.198384\n",
       "0         2000-01-05  4.269408\n",
       "...              ...       ...\n",
       "9         2001-05-08  6.136047\n",
       "9         2001-05-09  0.476046\n",
       "9         2001-05-10  1.334887\n",
       "9         2001-05-11  2.333404\n",
       "9         2001-05-12  3.005552\n",
       "\n",
       "[3007 rows x 2 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate Series - Takes 2 minutes to run\n",
    "#Only need to run this the first time\n",
    "from statsforecast.utils import generate_series\n",
    "#for length in [10_000, 100_000, 500_000, 1_000_000, 2_000_000]:\n",
    "#for length in [1_000]:\n",
    "for length in [10]:\n",
    "\t\tprint(f'length: {length}')\n",
    "\t\tseries = generate_series(n_series=length, seed=1)\n",
    "\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73ae1743",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'series' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Save series to Snowflake table\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Only need to run this the first time\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mseries\u001b[49m)\n\u001b[1;32m      4\u001b[0m df_reset \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      5\u001b[0m df_reset\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'series' is not defined"
     ]
    }
   ],
   "source": [
    "## Save series to Snowflake table\n",
    "#Only need to run this the first time\n",
    "df = pd.DataFrame(series)\n",
    "df_reset = df.reset_index()\n",
    "df_reset.columns = ['ID', 'DS', 'Y']\n",
    "\n",
    "test_df = session.create_dataframe(df_reset)\n",
    "test_df.write.mode('overwrite').save_as_table('TPCDS_XGBOOST.DEMO.Series2M')\n",
    "train_df = session.table('TPCDS_XGBOOST.DEMO.SERIES2M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ccd1a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "|\"ID\"    |\"DS\"                 |\"Y\"                    |\n",
      "--------------------------------------------------------\n",
      "|181695  |2000-02-22 00:00:00  |6.219272538160337      |\n",
      "|181695  |2000-02-23 00:00:00  |0.3076429294607981     |\n",
      "|181695  |2000-02-24 00:00:00  |1.197810254827208      |\n",
      "|181695  |2000-02-25 00:00:00  |2.173458515198763      |\n",
      "|181695  |2000-02-26 00:00:00  |3.102199405394565      |\n",
      "|181695  |2000-02-27 00:00:00  |4.376139372280642      |\n",
      "|181695  |2000-02-28 00:00:00  |5.375742028359614      |\n",
      "|181695  |2000-02-29 00:00:00  |6.147630148293396      |\n",
      "|181695  |2000-03-01 00:00:00  |0.0025383417716690615  |\n",
      "|181695  |2000-03-02 00:00:00  |1.0790424184236609     |\n",
      "--------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Retrieve from Snowflake -- \n",
    "train_df = session.table('TPCDS_XGBOOST.DEMO.SERIES2M')\n",
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fcaa282a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DS</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>0.167756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>1.282182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2.311294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>3.229050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>4.406428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278182</th>\n",
       "      <td>999</td>\n",
       "      <td>2000-07-28</td>\n",
       "      <td>2.039349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278183</th>\n",
       "      <td>999</td>\n",
       "      <td>2000-07-29</td>\n",
       "      <td>3.254294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278184</th>\n",
       "      <td>999</td>\n",
       "      <td>2000-07-30</td>\n",
       "      <td>4.152283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278185</th>\n",
       "      <td>999</td>\n",
       "      <td>2000-07-31</td>\n",
       "      <td>5.405954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278186</th>\n",
       "      <td>999</td>\n",
       "      <td>2000-08-01</td>\n",
       "      <td>6.281698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278187 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID         DS         Y\n",
       "0         0 2000-01-01  0.167756\n",
       "1         0 2000-01-02  1.282182\n",
       "2         0 2000-01-03  2.311294\n",
       "3         0 2000-01-04  3.229050\n",
       "4         0 2000-01-05  4.406428\n",
       "...     ...        ...       ...\n",
       "278182  999 2000-07-28  2.039349\n",
       "278183  999 2000-07-29  3.254294\n",
       "278184  999 2000-07-30  4.152283\n",
       "278185  999 2000-07-31  5.405954\n",
       "278186  999 2000-08-01  6.281698\n",
       "\n",
       "[278187 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(series)\n",
    "df_reset = df.reset_index()\n",
    "df_reset.columns = ['ID', 'DS', 'Y']\n",
    "df_reset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62a0b635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>FORECAST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-10-12</td>\n",
       "      <td>3.253695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-10-13</td>\n",
       "      <td>3.253667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-10-14</td>\n",
       "      <td>3.253638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-10-15</td>\n",
       "      <td>3.253610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-10-16</td>\n",
       "      <td>3.253582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000-10-17</td>\n",
       "      <td>3.253553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE  FORECAST\n",
       "0 2000-10-12  3.253695\n",
       "1 2000-10-13  3.253667\n",
       "2 2000-10-14  3.253638\n",
       "3 2000-10-15  3.253610\n",
       "4 2000-10-16  3.253582\n",
       "5 2000-10-17  3.253553"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Local Test for Exponential Smoothing\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "df = df_reset[df_reset['ID'] == 1]\n",
    "df.set_index('DS', inplace=True)\n",
    "model = ExponentialSmoothing(df['Y'], seasonal=None, trend='add', damped_trend=False)\n",
    "fit = model.fit()\n",
    "forecast = fit.forecast(steps=6)\n",
    "forecast_df = pd.DataFrame({\n",
    "                'DATE': forecast.index,\n",
    "                'FORECAST': forecast.values\n",
    "            })\n",
    "forecast_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e29f5036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m StatsForecast(models\u001b[38;5;241m=\u001b[39m[AutoARIMA(), Naive()],\n\u001b[1;32m      6\u001b[0m                       freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                       n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m df_reset\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m forecasts_df \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_reset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m forecasts_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/statsforecast/core.py:1486\u001b[0m, in \u001b[0;36mStatsForecast.forecast\u001b[0;34m(self, h, df, X_df, level, fitted, sort_df)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforecast\u001b[39m(\n\u001b[1;32m   1477\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1478\u001b[0m     h: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1483\u001b[0m     sort_df: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1484\u001b[0m ):\n\u001b[1;32m   1485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_native(df\u001b[38;5;241m=\u001b[39mdf):\n\u001b[0;32m-> 1486\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m            \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfitted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfitted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_df\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1489\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1490\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m fa\u001b[38;5;241m.\u001b[39mengine_context(infer_by\u001b[38;5;241m=\u001b[39m[df]) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/statsforecast/core.py:751\u001b[0m, in \u001b[0;36m_StatsForecast.forecast\u001b[0;34m(self, h, df, X_df, level, fitted, sort_df)\u001b[0m\n\u001b[1;32m    741\u001b[0m     res_fcsts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mga\u001b[38;5;241m.\u001b[39mforecast(\n\u001b[1;32m    742\u001b[0m         models\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels,\n\u001b[1;32m    743\u001b[0m         h\u001b[38;5;241m=\u001b[39mh,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    748\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    749\u001b[0m     )\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 751\u001b[0m     res_fcsts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forecast_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfitted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfitted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fitted:\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfcst_fitted_values_ \u001b[38;5;241m=\u001b[39m res_fcsts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfitted\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/statsforecast/core.py:1024\u001b[0m, in \u001b[0;36m_StatsForecast._forecast_parallel\u001b[0;34m(self, h, fitted, X, level)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     future \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mapply_async(\n\u001b[1;32m   1013\u001b[0m         ga\u001b[38;5;241m.\u001b[39mforecast,\n\u001b[1;32m   1014\u001b[0m         (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1021\u001b[0m         ),\n\u001b[1;32m   1022\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m     futures\u001b[38;5;241m.\u001b[39mappend(future)\n\u001b[0;32m-> 1024\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1025\u001b[0m fcsts \u001b[38;5;241m=\u001b[39m [d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforecasts\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m out]\n\u001b[1;32m   1026\u001b[0m fcsts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(fcsts)\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/statsforecast/core.py:1024\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     future \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mapply_async(\n\u001b[1;32m   1013\u001b[0m         ga\u001b[38;5;241m.\u001b[39mforecast,\n\u001b[1;32m   1014\u001b[0m         (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1021\u001b[0m         ),\n\u001b[1;32m   1022\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m     futures\u001b[38;5;241m.\u001b[39mappend(future)\n\u001b[0;32m-> 1024\u001b[0m out \u001b[38;5;241m=\u001b[39m [\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m futures]\n\u001b[1;32m   1025\u001b[0m fcsts \u001b[38;5;241m=\u001b[39m [d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforecasts\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m out]\n\u001b[1;32m   1026\u001b[0m fcsts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(fcsts)\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Local Test for Model\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import AutoARIMA, Naive\n",
    "\n",
    "model = StatsForecast(models=[AutoARIMA(), Naive()],\n",
    "                      freq='D',\n",
    "                      n_jobs=-1)\n",
    "df_reset.columns = ['unique_id', 'ds', 'y']\n",
    "forecasts_df = model.forecast(df=df_reset, h=7)\n",
    "forecasts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3571ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecastingModel(custom_model.CustomModel):\n",
    "\n",
    "    # Use the same decorator as for methods with FUNCTION inference.\n",
    "    @custom_model.partitioned_inference_api\n",
    "    def predict(self, df: pd.DataFrame) -> pd.DataFrame:        \n",
    "        from statsforecast import StatsForecast\n",
    "        from statsforecast.models import AutoARIMA, Naive\n",
    "        df.columns = ['unique_id', 'ds', 'y']\n",
    "        model = StatsForecast(models=[AutoARIMA()],\n",
    "                      freq='D',\n",
    "                      n_jobs=1)  ##chaning to 1 from -1\n",
    "\n",
    "        forecasts_df = model.forecast(df=df, h=7)\n",
    "        forecasts_df.columns = ['DSOUT', 'AUTOARIMA']\n",
    "\n",
    "        return forecasts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5fd5e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_forecasting_model = ForecastingModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "20f3d37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DSOUT</th>\n",
       "      <th>AUTOARIMA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-28</td>\n",
       "      <td>1.836878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-29</td>\n",
       "      <td>1.439913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-30</td>\n",
       "      <td>1.128735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-31</td>\n",
       "      <td>0.884806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>0.693591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2000-08-04</td>\n",
       "      <td>3.140651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2000-08-05</td>\n",
       "      <td>3.010512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2000-08-06</td>\n",
       "      <td>2.419422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2000-08-07</td>\n",
       "      <td>2.147971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2000-08-08</td>\n",
       "      <td>1.808624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DSOUT  AUTOARIMA\n",
       "unique_id                      \n",
       "0         2000-03-28   1.836878\n",
       "0         2000-03-29   1.439913\n",
       "0         2000-03-30   1.128735\n",
       "0         2000-03-31   0.884806\n",
       "0         2000-04-01   0.693591\n",
       "...              ...        ...\n",
       "999       2000-08-04   3.140651\n",
       "999       2000-08-05   3.010512\n",
       "999       2000-08-06   2.419422\n",
       "999       2000-08-07   2.147971\n",
       "999       2000-08-08   1.808624\n",
       "\n",
       "[7000 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_forecasting_model.predict(df_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1777249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ES Model\n",
    "class ForecastingModel(custom_model.CustomModel):\n",
    "    # Use the same decorator as for methods with FUNCTION inference.\n",
    "    @custom_model.inference_api\n",
    "    def predict(self, df:pd.DataFrame) -> pd.DataFrame:    #Please keep input and output here as pandas   \n",
    "        ################## Replace below with your python code ######################################## \n",
    "        import pandas as pd\n",
    "        from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "        from datetime import datetime, timedelta\n",
    "        print (df.head())\n",
    "        print (df.columns)\n",
    "        df = df.drop_duplicates(subset=['DS'])\n",
    "        df.set_index('DS', inplace=True)\n",
    "        df = df.asfreq('D') \n",
    "        model = ExponentialSmoothing(df['Y'], seasonal=None, trend='add', damped_trend=False,freq='D')\n",
    "        fit = model.fit()\n",
    "        forecast = fit.forecast(steps=7)\n",
    "        forecast_df = pd.DataFrame({\n",
    "                        'DATE': forecast.index,\n",
    "                        'FORECAST': forecast.values\n",
    "                    })\n",
    "        return forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ad073a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID         DS         Y\n",
      "87  1 2000-01-01  3.459974\n",
      "88  1 2000-01-02  4.034698\n",
      "89  1 2000-01-03  5.265729\n",
      "90  1 2000-01-04  6.292050\n",
      "91  1 2000-01-05  0.193316\n",
      "Index(['ID', 'DS', 'Y'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>FORECAST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-10-12</td>\n",
       "      <td>3.234706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-10-13</td>\n",
       "      <td>3.234599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-10-14</td>\n",
       "      <td>3.234492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-10-15</td>\n",
       "      <td>3.234385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-10-16</td>\n",
       "      <td>3.234278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000-10-17</td>\n",
       "      <td>3.234171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000-10-18</td>\n",
       "      <td>3.234064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE  FORECAST\n",
       "0 2000-10-12  3.234706\n",
       "1 2000-10-13  3.234599\n",
       "2 2000-10-14  3.234492\n",
       "3 2000-10-15  3.234385\n",
       "4 2000-10-16  3.234278\n",
       "5 2000-10-17  3.234171\n",
       "6 2000-10-18  3.234064"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_model = ForecastingModel()\n",
    "local_predictions = es_model.predict(df_reset[df_reset['ID'] == 1])\n",
    "local_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ec46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parallelize\n",
    "def parallel_predict(store_data, model):\n",
    "    return model.predict(store_data)\n",
    "\n",
    "# Assuming df1 is your complete dataset\n",
    "store_groups = [group for _, group in df_reset.groupby('ID')]\n",
    "\n",
    "# Initialize the ForecastingModel\n",
    "model = ForecastingModel()\n",
    "\n",
    "# Parallel execution using Joblib\n",
    "num_cores = -1  # Use all available cores\n",
    "results = Parallel(n_jobs=num_cores)(delayed(parallel_predict)(store_data, model) for store_data in store_groups)\n",
    "\n",
    "# Combine or process the results as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471b4d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"function_type\": \"TABLE_FUNCTION\",\n",
    "}\n",
    "\n",
    "mv = reg.log_model(\n",
    "    my_forecasting_model,\n",
    "    model_name=\"forecast\",\n",
    "    version_name=\"v13\",\n",
    "    conda_dependencies=[\"pandas\", \"scikit-learn\", \"xgboost\"],\n",
    "    options=options,\n",
    "    signatures={\n",
    "        \"predict\": model_signature.ModelSignature(\n",
    "            inputs=[\n",
    "                model_signature.FeatureSpec(name=\"EPOCH\", dtype=model_signature.DataType.DOUBLE),\n",
    "                model_signature.FeatureSpec(name=\"STORE_ID\", dtype=model_signature.DataType.DOUBLE),\n",
    "                model_signature.FeatureSpec(name=\"COLLEGE_TOWN\", dtype=model_signature.DataType.DOUBLE),\n",
    "                model_signature.FeatureSpec(name=\"HOURLY_TRAFFIC\", dtype=model_signature.DataType.INT64),\n",
    "            ],\n",
    "            outputs=[\n",
    "                model_signature.FeatureSpec(name=\"EPOCH_OUT\", dtype=model_signature.DataType.FLOAT),\n",
    "                model_signature.FeatureSpec(name=\"PREDICTION\", dtype=model_signature.DataType.FLOAT),\n",
    "            ],\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6be71cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/contextlib.py:137: UserWarning: `relax_version` is not set and therefore defaulted to True. Dependency version constraints relaxed from ==x.y.z to >=x.y, <(x+1). To use specific dependency versions for compatibility, reproducibility, etc., set `options={'relax_version': False}` when logging the model.\n",
      "  return next(self.gen)\n"
     ]
    }
   ],
   "source": [
    "options = {\n",
    "    \"function_type\": \"TABLE_FUNCTION\",\n",
    "}\n",
    "mv = reg.log_model(\n",
    "    es_model,\n",
    "    model_name=\"es_forecast\",\n",
    "    version_name=\"v7\",\n",
    "    conda_dependencies=['pandas', 'statsmodels', 'snowflake-snowpark-python'],\n",
    "    options=options,\n",
    "    #sample_input_data=df_reset[df_reset['ID'] == 1],\n",
    "    signatures={\n",
    "        \"predict\": model_signature.ModelSignature(\n",
    "            inputs=[\n",
    "                model_signature.FeatureSpec(name=\"ID\", dtype=model_signature.DataType.INT64),\n",
    "                model_signature.FeatureSpec(name=\"DS\", dtype=model_signature.DataType.TIMESTAMP_NTZ),\n",
    "                model_signature.FeatureSpec(name=\"Y\", dtype=model_signature.DataType.FLOAT),\n",
    "            ],\n",
    "            outputs=[\n",
    "                model_signature.FeatureSpec(name=\"DSOUT\", dtype=model_signature.DataType.TIMESTAMP_NTZ),\n",
    "                model_signature.FeatureSpec(name=\"FORECAST\", dtype=model_signature.DataType.FLOAT),\n",
    "            ],\n",
    "         )\n",
    "     },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "946f4f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/contextlib.py:137: UserWarning: `relax_version` is not set and therefore defaulted to True. Dependency version constraints relaxed from ==x.y.z to >=x.y, <(x+1). To use specific dependency versions for compatibility, reproducibility, etc., set `options={'relax_version': False}` when logging the model.\n",
      "  return next(self.gen)\n"
     ]
    }
   ],
   "source": [
    "options = {\n",
    "    \"function_type\": \"TABLE_FUNCTION\",\n",
    "}\n",
    "\n",
    "mv = reg.log_model(\n",
    "    my_forecasting_model,\n",
    "    model_name=\"statsforecast\",\n",
    "    version_name=\"v9\",\n",
    "    conda_dependencies=[\"pandas\", \"statsforecast\"],\n",
    "    options=options,\n",
    "    signatures={\n",
    "        \"predict\": model_signature.ModelSignature(\n",
    "            inputs=[\n",
    "                model_signature.FeatureSpec(name=\"ID\", dtype=model_signature.DataType.INT64),\n",
    "                model_signature.FeatureSpec(name=\"DS\", dtype=model_signature.DataType.TIMESTAMP_NTZ),\n",
    "                model_signature.FeatureSpec(name=\"Y\", dtype=model_signature.DataType.DOUBLE),\n",
    "            ],\n",
    "            outputs=[\n",
    "               # model_signature.FeatureSpec(name=\"ID\", dtype=model_signature.DataType.INT64),\n",
    "                model_signature.FeatureSpec(name=\"DSOUT\", dtype=model_signature.DataType.TIMESTAMP_NTZ),\n",
    "                model_signature.FeatureSpec(name=\"AUTOARIMA\", dtype=model_signature.DataType.FLOAT),\n",
    "            ],\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "940b535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg_model = reg.get_model(\"statsforecast\").version(\"v9\")\n",
    "reg_model = reg.get_model(\"es_forecast\").version(\"v7\")  #v8 is njobs=-1 and v9 is njobs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7639ff09",
   "metadata": {},
   "outputs": [
    {
     "ename": "SnowparkSQLException",
     "evalue": "(1300) (1304): 01b706a4-0002-ee9f-0023-fc8702c9c86a: 100357 (P0000): Expected 302 rows in the output given 302 rows in the input, but received 7 in function V7.PREDICT with handler predict.infer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSnowparkSQLException\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py:418\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 418\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/ml/model/_client/model/model_version_impl.py:443\u001b[0m, in \u001b[0;36mModelVersion.run\u001b[0;34m(self, X, service_name, function_name, partition_column, strict_input_validation)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_identifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSqlIdentifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_function_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod_function_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_function_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget_method_function_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_function_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msignature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mversion_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_version_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict_input_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict_input_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartition_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_partitioned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_function_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mis_partitioned\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/ml/model/_client/ops/model_ops.py:766\u001b[0m, in \u001b[0;36mModelOperator.invoke_method\u001b[0;34m(self, method_name, method_function_type, signature, X, database_name, schema_name, model_name, version_name, service_name, strict_input_validation, partition_column, statement_params, is_partitioned)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_order:\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;66;03m# if it's a partitioned table function, _ID will be null and we won't be able to sort.\u001b[39;00m\n\u001b[0;32m--> 766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdf_res\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_ID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    767\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    768\u001b[0m             formatting\u001b[38;5;241m.\u001b[39munwrap(\n\u001b[1;32m    769\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    775\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    776\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/telemetry.py:150\u001b[0m, in \u001b[0;36mdf_collect_api_telemetry.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mquery_history() \u001b[38;5;28;01mas\u001b[39;00m query_history:\n\u001b[0;32m--> 150\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m plan \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_select_statement \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_plan\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/dataframe.py:596\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self, statement_params, block, log_on_exception, case_sensitive)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m open_telemetry_context_manager(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollect, \u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_collect_with_tag_no_telemetry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/dataframe.py:644\u001b[0m, in \u001b[0;36mDataFrame._internal_collect_with_tag_no_telemetry\u001b[0;34m(self, statement_params, block, data_type, log_on_exception, case_sensitive)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_internal_collect_with_tag_no_telemetry\u001b[39m(\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# we should always call this method instead of collect(), to make sure the\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;66;03m# query tag is set properly.\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_statement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_or_update_statement_params_with_query_tag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_tag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m            \u001b[49m\u001b[43mSKIP_LEVELS_THREE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:513\u001b[0m, in \u001b[0;36mServerConnection.execute\u001b[0;34m(self, plan, to_pandas, to_iter, block, data_type, log_on_exception, case_sensitive, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsync query is not supported in stored procedure yet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    512\u001b[0m     )\n\u001b[0;32m--> 513\u001b[0m result_set, result_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block:\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:195\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m ne \u001b[38;5;241m=\u001b[39m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSQL_EXCEPTION_FROM_PROGRAMMING_ERROR(\n\u001b[1;32m    193\u001b[0m     e\n\u001b[1;32m    194\u001b[0m )\n\u001b[0;32m--> 195\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ne\u001b[38;5;241m.\u001b[39mwith_traceback(tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:126\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m snowflake\u001b[38;5;241m.\u001b[39mconnector\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mProgrammingError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:617\u001b[0m, in \u001b[0;36mServerConnection.get_result_set\u001b[0;34m(self, plan, to_pandas, to_iter, block, data_type, log_on_exception, case_sensitive, ignore_results, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m     final_query \u001b[38;5;241m=\u001b[39m final_query\u001b[38;5;241m.\u001b[39mreplace(holder, id_)\n\u001b[0;32m--> 617\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_ddl_on_temp_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_ddl_on_temp_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_job_plan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m placeholders[query\u001b[38;5;241m.\u001b[39mquery_id_place_holder] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    632\u001b[0m     result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last \u001b[38;5;28;01melse\u001b[39;00m result\u001b[38;5;241m.\u001b[39mquery_id\n\u001b[1;32m    633\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:123\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:117\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ReauthenticationRequest \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:418\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, ignore_results, **kwargs)\u001b[0m\n\u001b[1;32m    417\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to execute query\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_id_log\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# fetch_pandas_all/batches() only works for SELECT statements\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# We call fetchall() if fetch_pandas_all/batches() fails,\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;66;03m# because when the query plan has multiple queries, it will\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# have non-select statements, and it shouldn't fail if the user\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# calls to_pandas() to execute the query.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:403\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, ignore_results, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m--> 403\u001b[0m     results_cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_and_notify_query_listener\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecute query [queryID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_cursor\u001b[38;5;241m.\u001b[39msfqid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:354\u001b[0m, in \u001b[0;36mServerConnection.execute_and_notify_query_listener\u001b[0;34m(self, query, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_and_notify_query_listener\u001b[39m(\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SnowflakeCursor:\n\u001b[0;32m--> 354\u001b[0m     results_cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify_query_listeners(\n\u001b[1;32m    356\u001b[0m         QueryRecord(results_cursor\u001b[38;5;241m.\u001b[39msfqid, results_cursor\u001b[38;5;241m.\u001b[39mquery)\n\u001b[1;32m    357\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/connector/cursor.py:1087\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[0;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, _skip_upload_on_content_match, file_stream, num_statements, _dataframe_ast)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m IntegrityError \u001b[38;5;28;01mif\u001b[39;00m is_integrity_error \u001b[38;5;28;01melse\u001b[39;00m ProgrammingError\n\u001b[0;32m-> 1087\u001b[0m     \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/connector/errors.py:290\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m    exception to the first handler in that order.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m handed_over \u001b[38;5;241m=\u001b[39m \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhand_to_other_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handed_over:\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/connector/errors.py:345\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    344\u001b[0m cursor\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend((error_class, error_value))\n\u001b[0;32m--> 345\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/connector/errors.py:221\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    220\u001b[0m done_format_msg \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone_format_msg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error_class(\n\u001b[1;32m    222\u001b[0m     msg\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    223\u001b[0m     errno\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(errno),\n\u001b[1;32m    224\u001b[0m     sqlstate\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlstate\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    225\u001b[0m     sfqid\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    226\u001b[0m     query\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    227\u001b[0m     done_format_msg\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m done_format_msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(done_format_msg)\n\u001b[1;32m    229\u001b[0m     ),\n\u001b[1;32m    230\u001b[0m     connection\u001b[38;5;241m=\u001b[39mconnection,\n\u001b[1;32m    231\u001b[0m     cursor\u001b[38;5;241m=\u001b[39mcursor,\n\u001b[1;32m    232\u001b[0m )\n",
      "\u001b[0;31mSnowparkSQLException\u001b[0m: (1304): 01b706a4-0002-ee9f-0023-fc8702c9c86a: 100357 (P0000): Expected 302 rows in the output given 302 rows in the input, but received 7 in function V7.PREDICT with handler predict.infer",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSnowparkSQLException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#result = reg_model.run(df_reset, partition_column=\"ID\",function_name=\"PREDICT\").collect()\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mreg_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_reset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartition_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py:440\u001b[0m, in \u001b[0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m me\u001b[38;5;241m.\u001b[39moriginal_exception \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m me\u001b[38;5;241m.\u001b[39moriginal_exception \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m update_stmt_params_if_snowpark_df(res, statement_params)\n",
      "\u001b[0;31mSnowparkSQLException\u001b[0m: (1300) (1304): 01b706a4-0002-ee9f-0023-fc8702c9c86a: 100357 (P0000): Expected 302 rows in the output given 302 rows in the input, but received 7 in function V7.PREDICT with handler predict.infer"
     ]
    }
   ],
   "source": [
    "#result = reg_model.run(df_reset, partition_column=\"ID\",function_name=\"PREDICT\").collect()\n",
    "result = reg_model.run(df_reset, partition_column=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a7171598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DSOUT</th>\n",
       "      <th>AUTOARIMA</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6980</th>\n",
       "      <td>2000-02-22</td>\n",
       "      <td>2.007784</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6981</th>\n",
       "      <td>2000-02-23</td>\n",
       "      <td>1.581332</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6982</th>\n",
       "      <td>2000-02-24</td>\n",
       "      <td>1.245458</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6983</th>\n",
       "      <td>2000-02-25</td>\n",
       "      <td>0.980923</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6984</th>\n",
       "      <td>2000-02-26</td>\n",
       "      <td>0.772576</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6985</th>\n",
       "      <td>2000-02-27</td>\n",
       "      <td>0.608481</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6986</th>\n",
       "      <td>2000-02-29</td>\n",
       "      <td>3.189703</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>2.538254</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>2000-03-02</td>\n",
       "      <td>2.019854</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>2000-03-03</td>\n",
       "      <td>1.607329</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>2000-03-04</td>\n",
       "      <td>1.279056</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6991</th>\n",
       "      <td>2000-03-05</td>\n",
       "      <td>1.017828</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6992</th>\n",
       "      <td>2000-03-06</td>\n",
       "      <td>0.809952</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6993</th>\n",
       "      <td>2001-02-08</td>\n",
       "      <td>-0.719083</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6994</th>\n",
       "      <td>2001-02-09</td>\n",
       "      <td>0.427565</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>2001-02-10</td>\n",
       "      <td>-1.227083</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>2001-02-11</td>\n",
       "      <td>0.601691</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>2001-02-12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>2001-02-13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>2001-02-14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DSOUT  AUTOARIMA   ID\n",
       "6980 2000-02-22   2.007784   39\n",
       "6981 2000-02-23   1.581332   39\n",
       "6982 2000-02-24   1.245458   39\n",
       "6983 2000-02-25   0.980923   39\n",
       "6984 2000-02-26   0.772576   39\n",
       "6985 2000-02-27   0.608481   39\n",
       "6986 2000-02-29   3.189703  628\n",
       "6987 2000-03-01   2.538254  628\n",
       "6988 2000-03-02   2.019854  628\n",
       "6989 2000-03-03   1.607329  628\n",
       "6990 2000-03-04   1.279056  628\n",
       "6991 2000-03-05   1.017828  628\n",
       "6992 2000-03-06   0.809952  628\n",
       "6993 2001-02-08  -0.719083  995\n",
       "6994 2001-02-09   0.427565  995\n",
       "6995 2001-02-10  -1.227083  995\n",
       "6996 2001-02-11   0.601691  995\n",
       "6997 2001-02-12   0.000000  995\n",
       "6998 2001-02-13   0.000000  995\n",
       "6999 2001-02-14   0.000000  995"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b805074f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"SNOWPARK_OPT_WH\"\n"
     ]
    }
   ],
   "source": [
    "snowpark_opt_wh = Warehouse(\n",
    "  name=\"snowpark_opt_wh\",\n",
    "  warehouse_size=\"MEDIUM\",\n",
    "  warehouse_type = \"SNOWPARK-OPTIMIZED\",\n",
    "  auto_suspend=600,\n",
    ")\n",
    "warehouses = root.warehouses[\"snowpark_opt_wh\"]\n",
    "warehouses.create_or_alter(snowpark_opt_wh)\n",
    "session.use_warehouse(\"snowpark_opt_wh\")\n",
    "\n",
    "session.sql('alter session set USE_CACHED_RESULT = FALSE').collect()\n",
    "session.sql('alter session set query_tag = \"TS-LARGE-Chase\" ').collect()\n",
    "#session.sql('alter warehouse snowpark_opt_wh set max_concurrency_level = 1').collect()\n",
    "\n",
    "print(session.get_current_warehouse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fa8507f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "ename": "SnowparkSQLException",
     "evalue": "(1304): 01b7064c-0002-ee9f-0023-fc8702c9a136: 100357 (P0000): Expected 222 rows in the output given 222 rows in the input, but received 6 in function V3.PREDICT with handler predict.infer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSnowparkSQLException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m init \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Run the regression model\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mreg_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartition_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m total_time \u001b[38;5;241m=\u001b[39m (time() \u001b[38;5;241m-\u001b[39m init) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_series: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlength\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m total time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m total rows: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfiltered_df\u001b[38;5;241m.\u001b[39mcount()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/telemetry.py:150\u001b[0m, in \u001b[0;36mdf_collect_api_telemetry.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mquery_history() \u001b[38;5;28;01mas\u001b[39;00m query_history:\n\u001b[0;32m--> 150\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     plan \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_select_statement \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_plan\n\u001b[1;32m    152\u001b[0m     api_calls \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;241m*\u001b[39mplan\u001b[38;5;241m.\u001b[39mapi_calls,\n\u001b[1;32m    154\u001b[0m         {TelemetryField\u001b[38;5;241m.\u001b[39mNAME\u001b[38;5;241m.\u001b[39mvalue: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    155\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/dataframe.py:596\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self, statement_params, block, log_on_exception, case_sensitive)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Executes the query representing this DataFrame and returns the result as a\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;124;03mlist of :class:`Row` objects.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;124;03m    :meth:`collect_nowait()`\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m open_telemetry_context_manager(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollect, \u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_collect_with_tag_no_telemetry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/dataframe.py:644\u001b[0m, in \u001b[0;36mDataFrame._internal_collect_with_tag_no_telemetry\u001b[0;34m(self, statement_params, block, data_type, log_on_exception, case_sensitive)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_internal_collect_with_tag_no_telemetry\u001b[39m(\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# we should always call this method instead of collect(), to make sure the\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;66;03m# query tag is set properly.\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_statement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_or_update_statement_params_with_query_tag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_tag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m            \u001b[49m\u001b[43mSKIP_LEVELS_THREE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:513\u001b[0m, in \u001b[0;36mServerConnection.execute\u001b[0;34m(self, plan, to_pandas, to_iter, block, data_type, log_on_exception, case_sensitive, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    504\u001b[0m     is_in_stored_procedure()\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m     )\n\u001b[1;32m    509\u001b[0m ):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsync query is not supported in stored procedure yet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    512\u001b[0m     )\n\u001b[0;32m--> 513\u001b[0m result_set, result_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block:\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result_set\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:195\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     ne \u001b[38;5;241m=\u001b[39m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSQL_EXCEPTION_FROM_PROGRAMMING_ERROR(\n\u001b[1;32m    193\u001b[0m         e\n\u001b[1;32m    194\u001b[0m     )\n\u001b[0;32m--> 195\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ne\u001b[38;5;241m.\u001b[39mwith_traceback(tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:126\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m snowflake\u001b[38;5;241m.\u001b[39mconnector\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mProgrammingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    128\u001b[0m         query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:617\u001b[0m, in \u001b[0;36mServerConnection.get_result_set\u001b[0;34m(self, plan, to_pandas, to_iter, block, data_type, log_on_exception, case_sensitive, ignore_results, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m holder, id_ \u001b[38;5;129;01min\u001b[39;00m placeholders\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    616\u001b[0m     final_query \u001b[38;5;241m=\u001b[39m final_query\u001b[38;5;241m.\u001b[39mreplace(holder, id_)\n\u001b[0;32m--> 617\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_ddl_on_temp_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_ddl_on_temp_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_job_plan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m placeholders[query\u001b[38;5;241m.\u001b[39mquery_id_place_holder] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    632\u001b[0m     result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last \u001b[38;5;28;01melse\u001b[39;00m result\u001b[38;5;241m.\u001b[39mquery_id\n\u001b[1;32m    633\u001b[0m )\n\u001b[1;32m    634\u001b[0m result_meta \u001b[38;5;241m=\u001b[39m get_new_description(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cursor)\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:123\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[1;32m    120\u001b[0m         ex\u001b[38;5;241m.\u001b[39mcause\n\u001b[1;32m    121\u001b[0m     )\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:117\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_HAS_BEEN_CLOSED()\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ReauthenticationRequest \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[1;32m    120\u001b[0m         ex\u001b[38;5;241m.\u001b[39mcause\n\u001b[1;32m    121\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:418\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, ignore_results, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m         query_id_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m [queryID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;241m.\u001b[39msfqid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ex, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to execute query\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_id_log\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# fetch_pandas_all/batches() only works for SELECT statements\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# We call fetchall() if fetch_pandas_all/batches() fails,\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;66;03m# because when the query plan has multiple queries, it will\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# have non-select statements, and it shouldn't fail if the user\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# calls to_pandas() to execute the query.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:403\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, ignore_results, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_statement_params\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSNOWPARK_SKIP_TXN_COMMIT_IN_DDL\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m--> 403\u001b[0m     results_cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_and_notify_query_listener\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecute query [queryID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_cursor\u001b[38;5;241m.\u001b[39msfqid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:354\u001b[0m, in \u001b[0;36mServerConnection.execute_and_notify_query_listener\u001b[0;34m(self, query, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_and_notify_query_listener\u001b[39m(\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SnowflakeCursor:\n\u001b[0;32m--> 354\u001b[0m     results_cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify_query_listeners(\n\u001b[1;32m    356\u001b[0m         QueryRecord(results_cursor\u001b[38;5;241m.\u001b[39msfqid, results_cursor\u001b[38;5;241m.\u001b[39mquery)\n\u001b[1;32m    357\u001b[0m     )\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results_cursor\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/connector/cursor.py:1087\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[0;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, _skip_upload_on_content_match, file_stream, num_statements, _dataframe_ast)\u001b[0m\n\u001b[1;32m   1083\u001b[0m     is_integrity_error \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1084\u001b[0m         code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m100072\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1085\u001b[0m     )  \u001b[38;5;66;03m# NULL result in a non-nullable column\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m IntegrityError \u001b[38;5;28;01mif\u001b[39;00m is_integrity_error \u001b[38;5;28;01melse\u001b[39;00m ProgrammingError\n\u001b[0;32m-> 1087\u001b[0m     \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/connector/errors.py:290\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merrorhandler_wrapper\u001b[39m(\n\u001b[1;32m    269\u001b[0m     connection: SnowflakeConnection \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     error_value: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m        exception to the first handler in that order.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m     handed_over \u001b[38;5;241m=\u001b[39m \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhand_to_other_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handed_over:\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Error\u001b[38;5;241m.\u001b[39merrorhandler_make_exception(\n\u001b[1;32m    298\u001b[0m             error_class,\n\u001b[1;32m    299\u001b[0m             error_value,\n\u001b[1;32m    300\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/connector/errors.py:345\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    344\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend((error_class, error_value))\n\u001b[0;32m--> 345\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/working311/lib/python3.11/site-packages/snowflake/connector/errors.py:221\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    219\u001b[0m errno \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    220\u001b[0m done_format_msg \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone_format_msg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error_class(\n\u001b[1;32m    222\u001b[0m     msg\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    223\u001b[0m     errno\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(errno),\n\u001b[1;32m    224\u001b[0m     sqlstate\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlstate\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    225\u001b[0m     sfqid\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    226\u001b[0m     query\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    227\u001b[0m     done_format_msg\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m done_format_msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(done_format_msg)\n\u001b[1;32m    229\u001b[0m     ),\n\u001b[1;32m    230\u001b[0m     connection\u001b[38;5;241m=\u001b[39mconnection,\n\u001b[1;32m    231\u001b[0m     cursor\u001b[38;5;241m=\u001b[39mcursor,\n\u001b[1;32m    232\u001b[0m )\n",
      "\u001b[0;31mSnowparkSQLException\u001b[0m: (1304): 01b7064c-0002-ee9f-0023-fc8702c9a136: 100357 (P0000): Expected 222 rows in the output given 222 rows in the input, but received 6 in function V3.PREDICT with handler predict.infer"
     ]
    }
   ],
   "source": [
    "lengths = [10_000, 50_000, 100_000, 500_000, 1_000_000,2_000_000]\n",
    "lengths = [10_000]\n",
    "\n",
    "for length in lengths:\n",
    "  unique_ids_df = train_df.select(\"ID\").distinct().limit(length)\n",
    "  filtered_df = train_df.join(unique_ids_df, on=\"ID\", how=\"inner\").cache_result() #added cache result\n",
    "  print(unique_ids_df.count())\n",
    "  init = time()\n",
    "  # Run the regression model\n",
    "  result = reg_model.run(filtered_df, partition_column=\"ID\").collect()\n",
    "  total_time = (time() - init) / 60\n",
    "  print(f'n_series: {length} total time: {total_time} total rows: {filtered_df.count()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
