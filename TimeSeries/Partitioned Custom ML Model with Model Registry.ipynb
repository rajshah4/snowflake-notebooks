{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2452b045-2bcc-4df1-bfdf-6888c8320ed5",
   "metadata": {},
   "source": [
    "# Partitioned Custom ML Model with Model Registry\n",
    "\n",
    "This notebook includes two different models and datasets. They are both capable of being tested locally as well as run entirely in Snowflake. I have also made it so you can push the datasets into a Snowflake table for running the inference from the Snowflake model registry.\n",
    "\n",
    "### Partitioned restaurant traffic forecasting model\n",
    "\n",
    "The dataset is loaded locally from the `Partitioned_Custom_Model_Restaurant_Traffic_Data.csv` file.\n",
    "\n",
    "Change `\"MY_DB\"` and `\"MY_SCHEMA\"` to your desired existing database and schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28a2c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from snowflake.snowpark import Session\n",
    "from cryptography.hazmat.primitives import serialization\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "\n",
    "with open('../../creds.json') as f:\n",
    "    data = json.load(f)\n",
    "    USERNAME = data['user']\n",
    "    SF_ACCOUNT = data['account']\n",
    "    SF_WH = data['warehouse']\n",
    "    passphrase = data['passphrase']\n",
    "\n",
    "# Read the private key from the .p8 file\n",
    "with open('../../rsa_key.p8', 'rb') as key_file:\n",
    "    private_key = key_file.read()\n",
    "\n",
    "# If the private key is encrypted, load it with a passphrase\n",
    "# Replace 'your_key_passphrase' with your actual passphrase if needed\n",
    "private_key_obj = serialization.load_pem_private_key(\n",
    "    private_key,\n",
    "    password=passphrase.encode() if passphrase else None,\n",
    "    backend=default_backend()\n",
    ")\n",
    "\n",
    "# Define connection parameters including the private key\n",
    "CONNECTION_PARAMETERS = {\n",
    "    'user': USERNAME,\n",
    "    'account': SF_ACCOUNT,\n",
    "    'private_key': private_key_obj,\n",
    "    'warehouse': SF_WH,\n",
    "}\n",
    "\n",
    "# Create a session with the specified connection parameters\n",
    "session = Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "\n",
    "from snowflake.core.warehouse import Warehouse\n",
    "from snowflake.core import Root\n",
    "root = Root(session)\n",
    "from snowflake.snowpark.functions import col \n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e3b1e3f-fc07-4598-955b-063bbcb93efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from snowflake.ml.model import custom_model\n",
    "from snowflake.ml.model import model_signature\n",
    "from snowflake.ml.registry import registry\n",
    "from snowflake.ml.utils.connection_params import SnowflakeLoginOptions\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a437716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User                        : RSHAH\n",
      "Role                        : \"RAJIV\"\n",
      "Database                    : \"RAJIV\"\n",
      "Schema                      : \"PUBLIC\"\n",
      "Warehouse                   : \"RAJIV\"\n",
      "Snowflake version           : 8.30.2\n",
      "Snowpark for Python version : 1.20.0\n",
      "Snowflake ML version        : 1.6.1\n"
     ]
    }
   ],
   "source": [
    "from snowflake.snowpark.version import VERSION\n",
    "snowflake_environment = session.sql('select current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "from snowflake.ml import version\n",
    "mlversion = version.VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(session.get_current_role()))\n",
    "print('Database                    : {}'.format(session.get_current_database()))\n",
    "print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))\n",
    "print('Snowflake ML version        : {}.{}.{}'.format(mlversion[0],mlversion[2],mlversion[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4d5a9dd-a700-4de2-8065-4308678fd917",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTRY_DATABASE_NAME = \"TPCDS_XGBOOST\"\n",
    "REGISTRY_SCHEMA_NAME = \"DEMO\"\n",
    "reg = registry.Registry(session=session, database_name=REGISTRY_DATABASE_NAME, schema_name=REGISTRY_SCHEMA_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f78f580-67a0-4cce-b44e-f7c8424f9b43",
   "metadata": {},
   "source": [
    "#### The dataset contains an epoch timestamp in milliseconds, a store ID which will later be used as a partition column, a feature column `COLLEGE_TOWN`, and a target to be forecasted, `HOURLY_TRAFFIC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0a2387e2-0c09-4a56-893b-85d64e3f2657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "|\"EPOCH\"          |\"STORE_ID\"  |\"COLLEGE_TOWN\"  |\"HOURLY_TRAFFIC\"  |\n",
      "--------------------------------------------------------------------\n",
      "|1529154000000.0  |1.0         |1.0             |82                |\n",
      "|1529182800000.0  |1.0         |1.0             |2                 |\n",
      "|1529247600000.0  |1.0         |1.0             |35                |\n",
      "|1529269200000.0  |1.0         |1.0             |9                 |\n",
      "|1529326800000.0  |1.0         |1.0             |114               |\n",
      "|1529514000000.0  |1.0         |1.0             |24                |\n",
      "|1529697600000.0  |1.0         |1.0             |31                |\n",
      "|1529424000000.0  |1.0         |1.0             |28                |\n",
      "|1529575200000.0  |1.0         |1.0             |13                |\n",
      "|1529931600000.0  |1.0         |1.0             |110               |\n",
      "--------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data from csv file into pandas dataframe.\n",
    "test_df_pandas = pd.read_csv(\"Partitioned_Custom_Model_Restaurant_Traffic_Data.csv\")\n",
    "test_df = session.create_dataframe(test_df_pandas)\n",
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09535059",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.write.mode('overwrite').save_as_table('TPCDS_XGBOOST.DEMO.Restaurant_Traffic_Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e284ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = session.table('TPCDS_XGBOOST.DEMO.Restaurant_Traffic_Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca3e762",
   "metadata": {},
   "source": [
    "Data set is \n",
    "5209585 rows with 200 unique store IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "96b31eb8-d9c3-4257-993c-4544ddb7a14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    }
   ],
   "source": [
    "unique_store_count = test_df.select(test_df['STORE_ID']).distinct().count()\n",
    "print(unique_store_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7decef9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5209585"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "182ba1e0-370f-4cc8-86c4-dec4fc9f153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecastingModel(custom_model.CustomModel):\n",
    "\n",
    "    # Use the same decorator as for methods with FUNCTION inference.\n",
    "    @custom_model.partitioned_inference_api\n",
    "    def predict(self, df: pd.DataFrame) -> pd.DataFrame:        \n",
    "        import xgboost\n",
    "\n",
    "        # Set the time column as our index.\n",
    "        input_df = df.set_index('EPOCH')\n",
    "        input_df.index = pd.to_datetime(df['EPOCH'], unit='ms')\n",
    "\n",
    "        # Generate categorical features using the datetime index.\n",
    "        input_df['HOUR'] = input_df.index.hour.astype(\"category\")\n",
    "        input_df['DAY_OF_WEEK'] = input_df.index.dayofweek.astype(\"category\")\n",
    "        input_df['MONTH'] = input_df.index.month.astype(\"category\")\n",
    "        input_df['YEAR'] = input_df.index.year.astype(\"category\")\n",
    "        \n",
    "        input_df['COLLEGE_TOWN'] = input_df['COLLEGE_TOWN'].astype(\"category\")\n",
    "        \n",
    "        # Use get_dummies (one-hot encoding) for categorical features.\n",
    "        final = pd.get_dummies(data=input_df, columns=['COLLEGE_TOWN', 'HOUR', 'MONTH', 'YEAR', 'DAY_OF_WEEK'])\n",
    "\n",
    "        # Define the train & forecast split thresholds.\n",
    "        today = pd.to_datetime('2022-10-01')\n",
    "        yesterday = today - timedelta(days=1)\n",
    "        four_weeks = today + timedelta(days=28)\n",
    "        tomorrow = today + timedelta(days=1)\n",
    "\n",
    "        # Train data starts on June 16th 2018 and ends on September 30th.\n",
    "        train = final[(final.index >= pd.to_datetime('16-Jun-2018')) & (final.index <= pd.to_datetime(yesterday))]\n",
    "        \n",
    "        # The forecast starts from October 1st 2022 and goes 4 weeks into the future.\n",
    "        forecast = final[(final.index >= pd.to_datetime(tomorrow)) & (final.index <= pd.to_datetime(four_weeks))]\n",
    "\n",
    "        # Remove the target from the input dataset, and construct target dataset.\n",
    "        X_train = train.drop('HOURLY_TRAFFIC', axis=1)\n",
    "        y_train = train['HOURLY_TRAFFIC']\n",
    "\n",
    "        X_forecast = forecast.drop('HOURLY_TRAFFIC', axis=1)\n",
    "        \n",
    "        # Train an XGBoost regression model.\n",
    "        model = xgboost.XGBRegressor(n_estimators=200, n_jobs=1)\n",
    "        model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "        # Predict the hourly forecast for the future dates and make sure no predictions are less than zero.\n",
    "        forecast['PREDICTION'] = model.predict(X_forecast)\n",
    "        forecast['EPOCH_OUT'] = [t.value // 10**9 for t in forecast.index]\n",
    "        forecast = forecast[['EPOCH_OUT', 'PREDICTION']]\n",
    "        forecast = forecast.sort_index()\n",
    "        forecast.loc[forecast['PREDICTION'] < 0, 'PREDICTION'] = 0\n",
    "\n",
    "        return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8a8534f9-71db-4319-be58-5a9ff3f2fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_forecasting_model = ForecastingModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db5be5-6816-492d-991a-144a32d922ae",
   "metadata": {},
   "source": [
    "#### The predict method can be tested locally by using a pandas dataframe directly. Here we can run `predict` for a single partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d3b11059-8d8f-4023-a3a8-feaab66bd595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/f1b0hx_54t70j1szv_9_kt0c0000gn/T/ipykernel_91420/2495542525.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  forecast['PREDICTION'] = model.predict(X_forecast)\n",
      "/var/folders/wh/f1b0hx_54t70j1szv_9_kt0c0000gn/T/ipykernel_91420/2495542525.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  forecast['EPOCH_OUT'] = [t.value // 10**9 for t in forecast.index]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPOCH_OUT</th>\n",
       "      <th>PREDICTION</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPOCH</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-10-02 07:00:00</th>\n",
       "      <td>1664694000</td>\n",
       "      <td>77.787636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-02 08:00:00</th>\n",
       "      <td>1664697600</td>\n",
       "      <td>76.995056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-02 09:00:00</th>\n",
       "      <td>1664701200</td>\n",
       "      <td>76.751877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-02 10:00:00</th>\n",
       "      <td>1664704800</td>\n",
       "      <td>76.600456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-02 11:00:00</th>\n",
       "      <td>1664708400</td>\n",
       "      <td>96.709358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28 18:00:00</th>\n",
       "      <td>1666980000</td>\n",
       "      <td>30.727842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28 19:00:00</th>\n",
       "      <td>1666983600</td>\n",
       "      <td>30.608843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28 20:00:00</th>\n",
       "      <td>1666987200</td>\n",
       "      <td>31.198336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28 21:00:00</th>\n",
       "      <td>1666990800</td>\n",
       "      <td>4.420763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-28 22:00:00</th>\n",
       "      <td>1666994400</td>\n",
       "      <td>4.459415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>432 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      EPOCH_OUT  PREDICTION\n",
       "EPOCH                                      \n",
       "2022-10-02 07:00:00  1664694000   77.787636\n",
       "2022-10-02 08:00:00  1664697600   76.995056\n",
       "2022-10-02 09:00:00  1664701200   76.751877\n",
       "2022-10-02 10:00:00  1664704800   76.600456\n",
       "2022-10-02 11:00:00  1664708400   96.709358\n",
       "...                         ...         ...\n",
       "2022-10-28 18:00:00  1666980000   30.727842\n",
       "2022-10-28 19:00:00  1666983600   30.608843\n",
       "2022-10-28 20:00:00  1666987200   31.198336\n",
       "2022-10-28 21:00:00  1666990800    4.420763\n",
       "2022-10-28 22:00:00  1666994400    4.459415\n",
       "\n",
       "[432 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_forecasting_model.predict(test_df_pandas.loc[test_df_pandas['STORE_ID'] == 1])\n",
    "#my_forecasting_model.predict(test_df_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ad2585-c013-4730-b617-b2336d176479",
   "metadata": {},
   "source": [
    "#### Log the model, specifying the `function_type: \"TABLE_FUNCTION\"` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2e77f15-ae88-42fc-b6d3-e21665cd6fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/contextlib.py:137: UserWarning: `relax_version` is not set and therefore defaulted to True. Dependency version constraints relaxed from ==x.y.z to >=x.y, <(x+1). To use specific dependency versions for compatibility, reproducibility, etc., set `options={'relax_version': False}` when logging the model.\n",
      "  return next(self.gen)\n"
     ]
    }
   ],
   "source": [
    "options = {\n",
    "    \"function_type\": \"TABLE_FUNCTION\",\n",
    "}\n",
    "\n",
    "mv = reg.log_model(\n",
    "    my_forecasting_model,\n",
    "    model_name=\"forecast\",\n",
    "    version_name=\"v13\",\n",
    "    conda_dependencies=[\"pandas\", \"scikit-learn\", \"xgboost\"],\n",
    "    options=options,\n",
    "    signatures={\n",
    "        \"predict\": model_signature.ModelSignature(\n",
    "            inputs=[\n",
    "                model_signature.FeatureSpec(name=\"EPOCH\", dtype=model_signature.DataType.DOUBLE),\n",
    "                model_signature.FeatureSpec(name=\"STORE_ID\", dtype=model_signature.DataType.DOUBLE),\n",
    "                model_signature.FeatureSpec(name=\"COLLEGE_TOWN\", dtype=model_signature.DataType.DOUBLE),\n",
    "                model_signature.FeatureSpec(name=\"HOURLY_TRAFFIC\", dtype=model_signature.DataType.INT64),\n",
    "            ],\n",
    "            outputs=[\n",
    "                model_signature.FeatureSpec(name=\"EPOCH_OUT\", dtype=model_signature.DataType.FLOAT),\n",
    "                model_signature.FeatureSpec(name=\"PREDICTION\", dtype=model_signature.DataType.FLOAT),\n",
    "            ],\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fcde38-5b9d-4b96-8833-f699611c643b",
   "metadata": {},
   "source": [
    "#### Use the `run` method for inference, specifying the partition column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37a970ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = reg.get_model(\"forecast\").version(\"v13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a16f831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"SNOWPARK_OPT_WH\"\n"
     ]
    }
   ],
   "source": [
    "snowpark_opt_wh = Warehouse(\n",
    "  name=\"snowpark_opt_wh\",\n",
    "  warehouse_size=\"LARGE\",\n",
    "  warehouse_type = \"SNOWPARK-OPTIMIZED\",\n",
    "  auto_suspend=600,\n",
    ")\n",
    "warehouses = root.warehouses[\"snowpark_opt_wh\"]\n",
    "warehouses.create_or_alter(snowpark_opt_wh)\n",
    "\n",
    "session.sql('USE WAREHOUSE SNOWPARK_OPT_WH').collect()\n",
    "session.sql('alter session set USE_CACHED_RESULT = FALSE').collect()\n",
    "session.sql('alter session set query_tag = \"TS_XG_LARGE\" ').collect()\n",
    "print(session.get_current_warehouse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "53dda197-3afd-47a3-9fd6-d1237af6804f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPOCH_OUT</th>\n",
       "      <th>PREDICTION</th>\n",
       "      <th>STORE_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.664694e+09</td>\n",
       "      <td>74.812241</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.664698e+09</td>\n",
       "      <td>77.070419</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.664701e+09</td>\n",
       "      <td>75.961517</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.664705e+09</td>\n",
       "      <td>75.930870</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.664708e+09</td>\n",
       "      <td>96.267212</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86395</th>\n",
       "      <td>1.666980e+09</td>\n",
       "      <td>31.088211</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86396</th>\n",
       "      <td>1.666984e+09</td>\n",
       "      <td>30.569330</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86397</th>\n",
       "      <td>1.666987e+09</td>\n",
       "      <td>32.221611</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86398</th>\n",
       "      <td>1.666991e+09</td>\n",
       "      <td>6.004010</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86399</th>\n",
       "      <td>1.666994e+09</td>\n",
       "      <td>5.023667</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          EPOCH_OUT  PREDICTION  STORE_ID\n",
       "0      1.664694e+09   74.812241       7.0\n",
       "1      1.664698e+09   77.070419       7.0\n",
       "2      1.664701e+09   75.961517       7.0\n",
       "3      1.664705e+09   75.930870       7.0\n",
       "4      1.664708e+09   96.267212       7.0\n",
       "...             ...         ...       ...\n",
       "86395  1.666980e+09   31.088211      78.0\n",
       "86396  1.666984e+09   30.569330      78.0\n",
       "86397  1.666987e+09   32.221611      78.0\n",
       "86398  1.666991e+09    6.004010      78.0\n",
       "86399  1.666994e+09    5.023667      78.0\n",
       "\n",
       "[86400 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = mv.run(test_df, partition_column=\"STORE_ID\")\n",
    "result.select(\"EPOCH_OUT\", \"PREDICTION\", \"STORE_ID\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fc0df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimized S it ran in 24 seconds \n",
    "## Optimized M is ran in 21 seconds \n",
    "\n",
    "\n",
    "Raj test:\n",
    "## Optimized L ran in 15 seconds\n",
    "\n",
    "## Local test - one thread it ran in 1 minute 40 seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1593065f",
   "metadata": {},
   "source": [
    "### StatsForecast Arima Model on Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35ae7869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 10000\n",
      "length: 100000\n",
      "length: 500000\n",
      "length: 1000000\n",
      "length: 2000000\n"
     ]
    }
   ],
   "source": [
    "#Generate Series - Takes 2 minutes to run\n",
    "#Only need to run this the first time\n",
    "from statsforecast.utils import generate_series\n",
    "for length in [10_000, 100_000, 500_000, 1_000_000, 2_000_000]:\n",
    "\t\tprint(f'length: {length}')\n",
    "\t\tseries = generate_series(n_series=length, seed=1)\n",
    "\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73ae1743",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save series to Snowflake table\n",
    "#Only need to run this the first time\n",
    "df = pd.DataFrame(series)\n",
    "df_reset = df.reset_index()\n",
    "df_reset.columns = ['ID', 'DS', 'Y']\n",
    "\n",
    "test_df = session.create_dataframe(df_reset)\n",
    "test_df.write.mode('overwrite').save_as_table('TPCDS_XGBOOST.DEMO.Series2M')\n",
    "train_df = session.table('TPCDS_XGBOOST.DEMO.SERIES2M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ccd1a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "|\"ID\"    |\"DS\"                 |\"Y\"                    |\n",
      "--------------------------------------------------------\n",
      "|181695  |2000-02-22 00:00:00  |6.219272538160337      |\n",
      "|181695  |2000-02-23 00:00:00  |0.3076429294607981     |\n",
      "|181695  |2000-02-24 00:00:00  |1.197810254827208      |\n",
      "|181695  |2000-02-25 00:00:00  |2.173458515198763      |\n",
      "|181695  |2000-02-26 00:00:00  |3.102199405394565      |\n",
      "|181695  |2000-02-27 00:00:00  |4.376139372280642      |\n",
      "|181695  |2000-02-28 00:00:00  |5.375742028359614      |\n",
      "|181695  |2000-02-29 00:00:00  |6.147630148293396      |\n",
      "|181695  |2000-03-01 00:00:00  |0.0025383417716690615  |\n",
      "|181695  |2000-03-02 00:00:00  |1.0790424184236609     |\n",
      "--------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Retrieve from Snowflake -- \n",
    "train_df = session.table('TPCDS_XGBOOST.DEMO.SERIES2M')\n",
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e29f5036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>AutoARIMA</th>\n",
       "      <th>Naive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-28</td>\n",
       "      <td>1.626143</td>\n",
       "      <td>2.053747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-29</td>\n",
       "      <td>1.287569</td>\n",
       "      <td>2.053747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-30</td>\n",
       "      <td>1.019489</td>\n",
       "      <td>2.053747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-31</td>\n",
       "      <td>0.807224</td>\n",
       "      <td>2.053747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>0.639155</td>\n",
       "      <td>2.053747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds  AutoARIMA     Naive\n",
       "unique_id                                \n",
       "0         2000-03-28   1.626143  2.053747\n",
       "0         2000-03-29   1.287569  2.053747\n",
       "0         2000-03-30   1.019489  2.053747\n",
       "0         2000-03-31   0.807224  2.053747\n",
       "0         2000-04-01   0.639155  2.053747"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Local Test for Model\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import AutoARIMA, Naive\n",
    "\n",
    "model = StatsForecast(models=[AutoARIMA(), Naive()],\n",
    "                      freq='D',\n",
    "                      n_jobs=-1)\n",
    "df_reset.columns = ['unique_id', 'ds', 'y']\n",
    "forecasts_df = model.forecast(df=df_reset, h=7)\n",
    "forecasts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3571ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecastingModel(custom_model.CustomModel):\n",
    "\n",
    "    # Use the same decorator as for methods with FUNCTION inference.\n",
    "    @custom_model.partitioned_inference_api\n",
    "    def predict(self, df: pd.DataFrame) -> pd.DataFrame:        \n",
    "        from statsforecast import StatsForecast\n",
    "        from statsforecast.models import AutoARIMA, Naive\n",
    "        df.columns = ['unique_id', 'ds', 'y']\n",
    "        model = StatsForecast(models=[AutoARIMA()],\n",
    "                      freq='D',\n",
    "                      n_jobs=-1)\n",
    "\n",
    "        forecasts_df = model.forecast(df=df, h=7)\n",
    "        forecasts_df.columns = ['DSOUT', 'AUTOARIMA']\n",
    "\n",
    "        return forecasts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fd5e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_forecasting_model = ForecastingModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "20f3d37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n",
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/site-packages/numpy/core/numeric.py:330: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(a, fill_value, casting='unsafe')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DSOUT</th>\n",
       "      <th>AUTOARIMA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-28</td>\n",
       "      <td>1.626143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-29</td>\n",
       "      <td>1.287569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-30</td>\n",
       "      <td>1.019489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-03-31</td>\n",
       "      <td>0.807224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>0.639155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2000-08-30</td>\n",
       "      <td>3.246663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2000-08-31</td>\n",
       "      <td>2.810550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2000-09-01</td>\n",
       "      <td>2.433019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2000-09-02</td>\n",
       "      <td>2.106200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2000-09-03</td>\n",
       "      <td>1.823282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DSOUT  AUTOARIMA\n",
       "unique_id                      \n",
       "0         2000-03-28   1.626143\n",
       "0         2000-03-29   1.287569\n",
       "0         2000-03-30   1.019489\n",
       "0         2000-03-31   0.807224\n",
       "0         2000-04-01   0.639155\n",
       "...              ...        ...\n",
       "99        2000-08-30   3.246663\n",
       "99        2000-08-31   2.810550\n",
       "99        2000-09-01   2.433019\n",
       "99        2000-09-02   2.106200\n",
       "99        2000-09-03   1.823282\n",
       "\n",
       "[700 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_forecasting_model.predict(df_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "946f4f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajishah/anaconda3/envs/working311/lib/python3.11/contextlib.py:137: UserWarning: `relax_version` is not set and therefore defaulted to True. Dependency version constraints relaxed from ==x.y.z to >=x.y, <(x+1). To use specific dependency versions for compatibility, reproducibility, etc., set `options={'relax_version': False}` when logging the model.\n",
      "  return next(self.gen)\n"
     ]
    }
   ],
   "source": [
    "options = {\n",
    "    \"function_type\": \"TABLE_FUNCTION\",\n",
    "}\n",
    "\n",
    "mv = reg.log_model(\n",
    "    my_forecasting_model,\n",
    "    model_name=\"statsforecast\",\n",
    "    version_name=\"v8\",\n",
    "    conda_dependencies=[\"pandas\", \"statsforecast\"],\n",
    "    options=options,\n",
    "    signatures={\n",
    "        \"predict\": model_signature.ModelSignature(\n",
    "            inputs=[\n",
    "                model_signature.FeatureSpec(name=\"ID\", dtype=model_signature.DataType.INT64),\n",
    "                model_signature.FeatureSpec(name=\"DS\", dtype=model_signature.DataType.TIMESTAMP_NTZ),\n",
    "                model_signature.FeatureSpec(name=\"Y\", dtype=model_signature.DataType.DOUBLE),\n",
    "            ],\n",
    "            outputs=[\n",
    "               # model_signature.FeatureSpec(name=\"ID\", dtype=model_signature.DataType.INT64),\n",
    "                model_signature.FeatureSpec(name=\"DSOUT\", dtype=model_signature.DataType.TIMESTAMP_NTZ),\n",
    "                model_signature.FeatureSpec(name=\"AUTOARIMA\", dtype=model_signature.DataType.FLOAT),\n",
    "            ],\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "940b535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = reg.get_model(\"statsforecast\").version(\"v8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b805074f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"SNOWPARK_OPT_WH\"\n"
     ]
    }
   ],
   "source": [
    "snowpark_opt_wh = Warehouse(\n",
    "  name=\"snowpark_opt_wh\",\n",
    "  warehouse_size=\"LARGE\",\n",
    "  #warehouse_type = \"SNOWPARK-OPTIMIZED\",\n",
    "  auto_suspend=600,\n",
    ")\n",
    "warehouses = root.warehouses[\"snowpark_opt_wh\"]\n",
    "warehouses.create_or_alter(snowpark_opt_wh)\n",
    "session.use_warehouse(\"snowpark_opt_wh\")\n",
    "\n",
    "session.sql('alter session set USE_CACHED_RESULT = FALSE').collect()\n",
    "session.sql('alter session set query_tag = \"TS-LARGE\" ').collect()\n",
    "\n",
    "print(session.get_current_warehouse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa8507f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "n_series: 10000 total time: 72.435857351621 total rows: 2740194\n",
      "50000\n",
      "n_series: 50000 total time: 86.72789065043132 total rows: 13750257\n",
      "100000\n",
      "n_series: 100000 total time: 44.73047570387522 total rows: 27524168\n",
      "500000\n",
      "n_series: 500000 total time: 144.72759178082148 total rows: 137357685\n",
      "1000000\n",
      "n_series: 1000000 total time: 267.6801359653473 total rows: 274943496\n",
      "2000000\n",
      "n_series: 2000000 total time: 358.4139559308688 total rows: 549884998\n"
     ]
    }
   ],
   "source": [
    "lengths = [10_000, 50_000, 100_000, 500_000, 1_000_000,2_000_000]\n",
    "#lengths = [1_000_000]\n",
    "\n",
    "for length in lengths:\n",
    "  unique_ids_df = train_df.select(\"ID\").distinct().limit(length)\n",
    "  filtered_df = train_df.join(unique_ids_df, on=\"ID\", how=\"inner\")\n",
    "  print(unique_ids_df.count())\n",
    "  init = time()\n",
    "  # Run the regression model\n",
    "  result = reg_model.run(filtered_df, partition_column=\"ID\").collect()\n",
    "  total_time = (time() - init) / 60\n",
    "  print(f'n_series: {length} total time: {total_time} total rows: {filtered_df.count()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
